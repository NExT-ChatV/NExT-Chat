{
    "summary": "This code processes Flickr30kEntities dataset, extracts and organizes information from XML files, and flattens annotations for efficient data storage.",
    "details": [
        {
            "comment": "This code is parsing a sentence file from the Flickr30K Entities dataset and returning a list of dictionaries for each sentence. Each dictionary contains fields such as the original sentence, phrases (with their text, first word index, phrase ID, and phrase type), and coarse categories that the phrase belongs to.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/utils/flickr30k_entities_utils.py\":0-32",
            "content": "import os\nimport re\nimport xml.etree.ElementTree as ET\nfrom typing import Dict, List\nfrom tqdm import tqdm\ndef get_sentence_data(fn):\n    \"\"\"\n    Parses a sentence file from the Flickr30K Entities dataset\n    input:\n      fn - full file path to the sentence file to parse\n    output:\n      a list of dictionaries for each sentence with the following fields:\n          sentence - the original sentence\n          phrases - a list of dictionaries for each phrase with the\n                    following fields:\n                      phrase - the text of the annotated phrase\n                      first_word_index - the position of the first word of\n                                         the phrase in the sentence\n                      phrase_id - an identifier for this phrase\n                      phrase_type - a list of the coarse categories this \n                                    phrase belongs to\n    \"\"\"\n    with open(fn, 'r', encoding='utf8') as f:\n        sentences = f.read().split('\\n')\n    annotations = []\n    for sentence in sentences:"
        },
        {
            "comment": "This code is parsing sentences and extracting phrases. It identifies the beginning of a phrase by checking for '[', then adds words to the current phrase until it finds ']'. The extracted phrases are stored in a list, along with their type and id. Finally, the original sentence and its parsed phrases are stored in a dictionary.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/utils/flickr30k_entities_utils.py\":33-65",
            "content": "        if not sentence:\n            continue\n        first_word = []\n        phrases = []\n        phrase_id = []\n        phrase_type = []\n        words = []\n        current_phrase = []\n        add_to_phrase = False\n        for token in sentence.split():\n            if add_to_phrase:\n                if token[-1] == ']':\n                    add_to_phrase = False\n                    token = token[:-1]\n                    current_phrase.append(token)\n                    phrases.append(' '.join(current_phrase))\n                    current_phrase = []\n                else:\n                    current_phrase.append(token)\n                words.append(token)\n            else:\n                if token[0] == '[':\n                    add_to_phrase = True\n                    first_word.append(len(words))\n                    parts = token.split('/')\n                    phrase_id.append(parts[1][3:])\n                    phrase_type.append(parts[2:])\n                else:\n                    words.append(token)\n        sentence_data = {'sentence': ' '.join(words), 'phrases': []}"
        },
        {
            "comment": "The code parses Flickr30K Entities dataset XML files, extracting scene identifiers, non-visible identifiers, and box coordinates for each identifier. It stores the extracted information in a dictionary format with appropriate fields.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/utils/flickr30k_entities_utils.py\":66-92",
            "content": "        for index, phrase, p_id, p_type in zip(first_word, phrases, phrase_id, phrase_type):\n            sentence_data['phrases'].append({'first_word_index': index,\n                                             'phrase': phrase,\n                                             'phrase_id': p_id,\n                                             'phrase_type': p_type})\n        annotations.append(sentence_data)\n    return annotations\ndef get_annotations(fn):\n    \"\"\"\n    Parses the xml files in the Flickr30K Entities dataset\n    input:\n      fn - full file path to the annotations file to parse\n    output:\n      dictionary with the following fields:\n          scene - list of identifiers which were annotated as\n                  pertaining to the whole scene\n          nobox - list of identifiers which were annotated as\n                  not being visible in the image\n          boxes - a dictionary where the fields are identifiers\n                  and the values are its list of boxes in the \n                  [xmin ymin xmax ymax] format"
        },
        {
            "comment": "This code parses an XML file and extracts information about objects, their bounding boxes, and 'nobox' labels. It initializes a dictionary for storing the extracted data including object sizes, box coordinates, and 'nobox' labels. If a box ID is not already in the dictionary, it creates an empty list to store its coordinates. Then, it extracts the bounding box coordinates and adjusts them by subtracting 1. For objects without bounding boxes, it adds their 'nobndbox' label to the dictionary.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/utils/flickr30k_entities_utils.py\":93-114",
            "content": "    \"\"\"\n    tree = ET.parse(fn)\n    root = tree.getroot()\n    size_container = root.findall('size')[0]\n    anno_info = {'boxes': {}, 'scene': [], 'nobox': []}\n    for size_element in size_container:\n        anno_info[size_element.tag] = int(size_element.text)\n    for object_container in root.findall('object'):\n        for names in object_container.findall('name'):\n            box_id = names.text\n            box_container = object_container.findall('bndbox')\n            if len(box_container) > 0:\n                if box_id not in anno_info['boxes']:\n                    anno_info['boxes'][box_id] = []\n                xmin = int(box_container[0].findall('xmin')[0].text) - 1\n                ymin = int(box_container[0].findall('ymin')[0].text) - 1\n                xmax = int(box_container[0].findall('xmax')[0].text) - 1\n                ymax = int(box_container[0].findall('ymax')[0].text) - 1\n                anno_info['boxes'][box_id].append([xmin, ymin, xmax, ymax])\n            else:\n                nobndbox = int(object_container.findall('nobndbox')[0].text)"
        },
        {
            "comment": "Function flattens annotations for a given index list, retrieves information from .xml and .txt files, and appends them to the data list. It processes each index in the list using tqdm progress bar, gets the annotation path, sentence path, loads annotations, and extracts sentence data.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/utils/flickr30k_entities_utils.py\":115-152",
            "content": "                if nobndbox > 0:\n                    anno_info['nobox'].append(box_id)\n                scene = int(object_container.findall('scene')[0].text)\n                if scene > 0:\n                    anno_info['scene'].append(box_id)\n    return anno_info\ndef get_ann_path(idx, *, annotation_dir=\"\"):\n    return os.path.join(annotation_dir, rf'Annotations/{idx}.xml')\ndef get_sen_path(idx, *, annotation_dir=\"\"):\n    return os.path.join(annotation_dir, rf\"Sentences/{idx}.txt\")\ndef get_img_path(idx, *, image_dir=\"\"):\n    return os.path.join(image_dir, rf'{idx}.jpg')\nPHRASE_ST_PLACEHOLDER = '<ph_st>'\nPHRASE_ED_PLACEHOLDER = '<ph_ed>'\ndef flatten_annotation(annotation_dir, indexes):\n    data = []\n    for index in tqdm(indexes):\n        image_id = index\n        ann_path = get_ann_path(index, annotation_dir=annotation_dir)\n        sen_path = get_sen_path(index, annotation_dir=annotation_dir)\n        anns = get_annotations(ann_path)\n        sens = get_sentence_data(sen_path)\n        for sen in sens:\n           "
        },
        {
            "comment": "Iterates through sentences, filters phrase IDs present in 'anns'['boxes'], maps filtered phrase IDs to box coordinates, stores box sequences for phrases with corresponding IDs, and creates a list of sentence words.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/utils/flickr30k_entities_utils.py\":152-174",
            "content": " pids = list(set(phrase['phrase_id'] for phrase in sen['phrases'] if phrase['phrase_id'] in anns['boxes']))\n            boxes_mapping: Dict[str, List[int]] = {}\n            boxes_filtered: List[List[int]] = []\n            for pid in pids:\n                v = anns['boxes'][pid]\n                mapping = []\n                for box in v:\n                    mapping.append(len(boxes_filtered))\n                    boxes_filtered.append(box)\n                boxes_mapping[pid] = mapping\n            boxes_seq: List[List[int]] = []\n            for phrase in sen['phrases']:\n                if not phrase['phrase_id'] in anns['boxes']:\n                    continue\n                pid = phrase['phrase_id']\n                boxes_seq.append(boxes_mapping[pid])\n            sent = list(sen['sentence'].split())\n            for phrase in sen['phrases'][::-1]:\n                if not phrase['phrase_id'] in anns['boxes']:\n                    continue\n                span = [phrase['first_word_index'], phrase['first_word_index'] + len(phrase['phrase'].split())]"
        },
        {
            "comment": "This code processes the Flickr30kEntities dataset, replacing phrase spans with placeholders and converting sentences to a required format for further processing. It ensures correct placement of placeholders and validates the sentence against ground truth. Finally, it appends the processed data into a list before returning.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/utils/flickr30k_entities_utils.py\":175-199",
            "content": "                sent[span[0]:span[1]] = [f\"{PHRASE_ST_PLACEHOLDER}{' '.join(sent[span[0]:span[1]])}{PHRASE_ED_PLACEHOLDER}\"]\n            sent_converted = \" \".join(sent)\n            assert len(re.findall(PHRASE_ST_PLACEHOLDER, sent_converted)) \\\n                   == len(re.findall(PHRASE_ED_PLACEHOLDER, sent_converted)) \\\n                   == len(boxes_seq), f\"error when parse: {sent_converted}, {boxes_seq}, {sen}, {anns}\"\n            assert sent_converted.replace(PHRASE_ST_PLACEHOLDER, \"\").replace(PHRASE_ED_PLACEHOLDER, \"\") == sen['sentence']\n            item = {\n                'id': len(data),\n                'image_id': image_id,\n                'boxes': boxes_filtered,\n                'sentence': sent_converted,\n                'boxes_seq': boxes_seq,\n            }\n            data.append(item)\n    return data\nif __name__ == '__main__':\n    filenames = [\n        r'D:\\home\\dataset\\flickr30kentities\\train.txt',\n        r'D:\\home\\dataset\\flickr30kentities\\val.txt',\n        r'D:\\home\\dataset\\flickr30kentities\\test.txt',"
        },
        {
            "comment": "This code reads filenames, then for each filename it opens the file in read mode, converts lines to a list of stripped strings, and finally calls flatten_annotation function passing annotation_dir and indexes as arguments.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/utils/flickr30k_entities_utils.py\":200-204",
            "content": "    ]\n    for filename in filenames:\n        annotation_dir = r'D:\\home\\dataset\\flickr30kentities'\n        indexes = [line.strip() for line in open(filename, 'r', encoding='utf8')]\n        flatten_annotation(annotation_dir, indexes)"
        }
    ]
}