{
    "summary": "This code processes chat conversations and images for AI models by tokenizing, generating input_ids, preprocessing images, and creating attention masks and labels. It inherits from BaseConvProcessFunc and utilizes Conversation and LlamaTokenizer.",
    "details": [
        {
            "comment": "This code is a Python class for processing conversations, specifically for a chat-based task. It inherits from the BaseConvProcessFunc class and contains a call method that takes in a list of raw conversation dictionaries, a preprocessor dictionary, and a Conversation object as input. The output is a processed list of conversation dictionaries. The code also includes various constants and logging setup.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/chat_process_function.py\":0-39",
            "content": "import sys\nimport copy\nimport warnings\nimport logging\nfrom typing import Dict, Any, List\nimport PIL.Image\nimport torch\nfrom PIL import Image\nfrom transformers import LlamaTokenizer\nfrom ..root import (\n    FUNCTIONS,\n    IMAGE_PLACEHOLDER,\n    BaseImageProcessFunc,\n    BaseConvProcessFunc,\n    BaseTextProcessFunc,\n)\nfrom ...conversation import SeparatorStyle, Conversation\nIGNORE_INDEX = -100\nDEFAULT_IMAGE_TOKEN = IMAGE_PLACEHOLDER\nDEFAULT_IMAGE_PATCH_TOKEN = \"<im_patch>\"\nDEFAULT_IM_START_TOKEN = \"<im_start>\"\nDEFAULT_IM_END_TOKEN = \"<im_end>\"\nDEFAULT_AT_TOKEN = \"<at>\"\nDEFAULT_BOXES_TOKEN = \"<boxes>\"\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nlogging.basicConfig(\n    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n    datefmt=\"%m/%d/%Y %H:%M:%S\",\n    handlers=[logging.StreamHandler(sys.stdout), ],\n)\n@FUNCTIONS.register_module()\nclass ChatConvProcess(BaseConvProcessFunc):\n    def __call__(self, raw_conv: List[Dict[str, Any]], preprocessor: Dict[str, Any], conv_template: Conversation) -> List[Dict[str, Any]]:"
        },
        {
            "comment": "The code retrieves configuration parameters from the preprocessor dictionary, performs assertions on available tokens, and adjusts the raw conversation data if a specific separation token is used for images. The code handles image-related tokens, replacing them with appropriate formats based on the provided configuration.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/chat_process_function.py\":40-56",
            "content": "        conv_processor_cfg = preprocessor['conv']\n        image_token_len = conv_processor_cfg['image_token_len']\n        sep_image_conv_front = conv_processor_cfg.get('sep_image_conv_front', False)\n        use_im_start_end = conv_processor_cfg.get('use_im_start_end', False)\n        # assert DEFAULT_IMAGE_PATCH_TOKEN in preprocessor['text'].get_vocab()\n        # if use_im_start_end:\n        #     assert DEFAULT_IM_START_TOKEN in preprocessor['text'].get_vocab()\n        #     assert DEFAULT_IM_END_TOKEN in preprocessor['text'].get_vocab()\n        if sep_image_conv_front:\n            raw_conv[0]['value'] = raw_conv[0]['value'].replace(DEFAULT_IMAGE_TOKEN, '').strip()\n            raw_conv[0]['value'] = DEFAULT_IMAGE_TOKEN + conv_template.sep + conv_template.roles[0] + \": \" + raw_conv[0]['value']\n        for sentence in raw_conv:\n            replace_token = DEFAULT_IMAGE_PATCH_TOKEN * image_token_len\n            if use_im_start_end:\n                replace_token = DEFAULT_IM_START_TOKEN + replace_token + DEFAULT_IM_END_TOKEN"
        },
        {
            "comment": "This code registers a ChatTextProcess function, which processes conversation data. The function takes a Conversation object and LlamaTokenizer as input parameters. It can handle different separator styles and returns tokenized conversation data. If truncation size is not set, the function returns the processed conversation.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/chat_process_function.py\":57-82",
            "content": "            sentence[\"value\"] = sentence[\"value\"].replace(DEFAULT_IMAGE_TOKEN, replace_token)\n        return raw_conv\n@FUNCTIONS.register_module()\nclass ChatTextProcess(BaseTextProcessFunc):\n    def __call__(self, conv: Conversation, preprocessor: Dict[str, Any], mode: str, **tokenize_kwargs) -> Dict[str, Any]:\n        tokenizer = preprocessor['text']\n        assert isinstance(tokenizer, LlamaTokenizer), \"only work for LlamaTokenizer\"\n        _truncation_size = tokenize_kwargs.pop('truncation_size', None)\n        _kwargs = {'return_tensors': 'pt'}\n        _kwargs.update(tokenize_kwargs)\n        if conv.sep_style == SeparatorStyle.ADD_COLON_TWO:\n            if mode in ['train']:\n                ret = self.tk_conv_colon_two_train(conv, tokenizer, **_kwargs)\n            else:\n                ret = self.tk_conv_colon_two_eval(conv, tokenizer, **_kwargs)\n        else:\n            raise ValueError(f\"unrecognized conv_style: {conv.sep_style}.\\n the conv is {conv}\")\n        if _truncation_size is None:\n            return ret"
        },
        {
            "comment": "The code checks if the length of input_ids in 'ret' is less than or equal to _truncation_size. If it is, it returns 'ret'. Otherwise, it determines which ids to remove to truncate the text while ensuring important image tokens are not removed. It then creates a list of target indices (tgt_ids) by either including all indices if there are no images in the remaining text or by iterating backwards from the end and excluding non-image token ids until reaching the required number of ids to remove.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/chat_process_function.py\":83-103",
            "content": "        if len(ret['input_ids']) <= _truncation_size:\n            return ret\n        origin_len = len(ret['input_ids'])\n        ids_to_remove_num = origin_len - _truncation_size\n        # truncation. should carefully not truncate <img_token>\n        ids_should_not_remove = list(map(\n            tokenizer.convert_tokens_to_ids,\n            (DEFAULT_IMAGE_PATCH_TOKEN, DEFAULT_IM_END_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_BOXES_TOKEN, DEFAULT_AT_TOKEN)\n        ))\n        back_no_image = all(ids not in ids_should_not_remove for ids in ret['input_ids'][_truncation_size:])\n        if back_no_image:\n            tgt_ids = list(range(_truncation_size))\n        else:\n            ids_to_remove = set()\n            for idx in range(origin_len - 1, -1, -1):\n                if ret['input_ids'][idx] not in ids_should_not_remove:\n                    ids_to_remove.add(idx)\n                    if len(ids_to_remove) >= ids_to_remove_num:\n                        break\n            tgt_ids = [_ for _ in range(origin_len) if _ not in ids_to_remove]"
        },
        {
            "comment": "This function truncates a sample and returns the truncated input_ids. It first logs a warning if the sample size is larger than expected, then asserts that the tgt_ids length matches the desired truncation size. Next, it creates a new dictionary, truncated_ret, containing only keys from ret, and values are the corresponding items in the original ret, but limited to the range of tgt_ids. Finally, it returns the truncated_ret. The function tk_conv_colon_two_train takes a conversation, tokenizer and other arguments as input and returns masked targets for a specific conversation style (add colon two). It starts by asserting that the conv's sep_style is add colon two. Then it masks the target tokens using the separator, ensuring that all non-pad tokens are marked with IGNORE_INDEX, except for the first one which is left unchanged. The function loops through the conversation rounds (split by sep2) and if a round contains both speaker and role information (split by conv.sep), it continues processing; otherwise, it breaks out of the loop. It then creates target tokens using the speaker and role information in each round.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/chat_process_function.py\":104-126",
            "content": "        logger.warning(f\"truncate sample size from {origin_len} to {len(tgt_ids)}.\")\n        assert len(tgt_ids) == _truncation_size, f\"{len(tgt_ids)}, {_truncation_size}, {ret['input_ids'].tolist()}\"\n        truncated_ret = {k: v[tgt_ids] for k, v in ret.items()}\n        return truncated_ret\n    # noinspection PyMethodMayBeStatic\n    def tk_conv_colon_two_train(self, conv, tokenizer, **kwargs):\n        conversation = conv.get_prompt()\n        input_ids = tokenizer([conversation, ], **kwargs).input_ids[0]\n        target = copy.deepcopy(input_ids)\n        assert conv.sep_style == SeparatorStyle.ADD_COLON_TWO\n        # Mask targets\n        sep = conv.sep + conv.roles[1] + \": \"\n        total_len = int(target.ne(tokenizer.pad_token_id).sum())\n        rounds = conversation.split(conv.sep2)\n        cur_len = 1\n        target[:cur_len] = IGNORE_INDEX\n        for i, rou in enumerate(rounds):\n            if rou == \"\":\n                break\n            parts = rou.split(sep)\n            if len(parts) != 2:\n                break"
        },
        {
            "comment": "This code is processing a chat conversation by tokenizing the messages and creating input_ids for a model. It first joins all messages with a separator, calculates the lengths of instruction and round tokens, ignores extra tokens if exceeding maximum length, and creates dictionaries containing input_ids, attention_mask, and labels for further processing.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/chat_process_function.py\":127-151",
            "content": "            parts[0] += sep\n            round_len = len(tokenizer(rou).input_ids)\n            instruction_len = len(tokenizer(parts[0]).input_ids) - 2  # <s> <space>\n            target[cur_len: cur_len + instruction_len] = IGNORE_INDEX\n            cur_len += round_len\n        target[cur_len:] = IGNORE_INDEX\n        # if cur_len < tokenizer.model_max_length:\n        #     if cur_len != total_len:\n        #         target[:] = IGNORE_INDEX\n        #         warnings.warn(f\"WARNING: tokenization mismatch: {cur_len} vs. {total_len}. (ignored):\\n{conversation}\")\n        return dict(\n            input_ids=input_ids,\n            attention_mask=input_ids.ne(tokenizer.pad_token_id),\n            labels=target,\n        )\n    # noinspection PyMethodMayBeStatic\n    def tk_conv_colon_two_eval(self, conv, tokenizer, **kwargs):\n        assert len(conv.messages) >= 2\n        # target = conv.messages[-1][-1]\n        target = conv.get_prompt()\n        conv.messages[-1][-1] = \"\"\n        conversation = conv.get_prompt()\n        input_ids = tokenizer([conversation, ], **kwargs).input_ids[0]"
        },
        {
            "comment": "This code processes an image by using a predefined processor to perform necessary preprocessing before feeding it into the model. It ensures the image is of correct format and size, and converts it into tensor format for the model's input. The function returns the processed image along with its attention mask and target labels if applicable.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/chat_process_function.py\":153-175",
            "content": "        target = tokenizer([target, ], add_special_tokens=False, **kwargs).input_ids[0]\n        target[target == tokenizer.pad_token_id] = IGNORE_INDEX\n        return dict(\n            input_ids=input_ids,\n            attention_mask=input_ids.ne(tokenizer.pad_token_id),\n            labels=target,\n        )\n@FUNCTIONS.register_module()\nclass ChatImageProcessor(BaseImageProcessFunc):\n    def __call__(self, image: Image.Image, preprocessor: Dict[str, Any]) -> Dict[str, Any]:\n        image_processor = preprocessor['image']\n        if isinstance(image, (list, tuple)):\n            image = image_processor.preprocess(image, return_tensors='pt')['pixel_values']\n            assert False, 'NExTChat not support MultiImage'\n        elif isinstance(image, PIL.Image.Image):\n            image = image_processor.preprocess(image, return_tensors='pt')['pixel_values'][0]\n        else:\n            if hasattr(image_processor, 'crop_size'):\n                crop_size = image_processor.crop_size\n                height, width = crop_size['height'], crop_size['width']"
        },
        {
            "comment": "This code raises a ValueError if the input image is empty, and then creates a zero-filled image of size 3xheightxwidth as a placeholder for padding. The function returns a dictionary with the placeholder image under the key 'image'.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/chat_process_function.py\":176-179",
            "content": "            else:\n                raise ValueError(\"got empty image. and don't know how to pad\")\n            image = torch.zeros(3, height, width)\n        return {'image': image}"
        }
    ]
}