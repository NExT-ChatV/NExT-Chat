{
    "summary": "The code is launching the accelerate library with 8 processes and specifying CUDA visible devices. It then executes `mllm/pipeline/finetune.py` using a specific configuration file `config/nextchat_eval_multi_res.py`. The model's output directory is set to \"$MODEL_PATH\"/res/, and the per-device evaluation batch size is 1.",
    "details": [
        {
            "comment": "The code is launching the accelerate library with 8 processes and specifying CUDA visible devices. It then executes `mllm/pipeline/finetune.py` using a specific configuration file `config/nextchat_eval_multi_res.py`. The model's output directory is set to \"$MODEL_PATH\"/res/, and the per-device evaluation batch size is 1.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/eval_res.sh\":0-7",
            "content": "MODEL_PATH=$1\nCUDA_VISIBLE_DEVICES=\"0,1,2,3,4,5,6,7\" accelerate launch --num_processes 8 \\\n        --main_process_port 23781 \\\n        mllm/pipeline/finetune.py \\\n        config/nextchat_eval_multi_res.py \\\n        --cfg-options model_args.model_name_or_path=$MODEL_PATH model_args.mm_projector_depth=2 \\\n        --output_dir \"$MODEL_PATH\"/res/  --per_device_eval_batch_size 1"
        }
    ]
}