{
    "summary": "BoxFormatProcess normalizes box format in NExT-Chat, while TokenFormatter processes bounding boxes, annotates text data, and includes methods for special tokens. Both classes are combined to create a model with preprocessor and target processor assigned.",
    "details": [
        {
            "comment": "This code defines a function, BoxFormatProcess, that takes in raw conversation data and a target dictionary with boxes information. It also accepts optional multimage mode argument. The function normalizes the box format, registers it as a module, and returns a tuple containing updated conversation data and the target dictionary. The preprocessor dictionary is used to define how the target's boxes should be processed. This function is part of the NExT-Chat framework for multi-modal large language models.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":0-38",
            "content": "import re\nimport sys\nimport logging\nimport typing\nfrom typing import List, Dict, Any, Tuple, Union\nfrom ..utils.transform import norm_box_xyxy, norm_point_xyxy\nfrom ..root import (\n    FUNCTIONS,\n    BaseTargetProcessFunc,\n    BOXES_PLACEHOLDER,\n    BOXES_PROCESSOR,\n    POINTS_PLACEHOLDER,\n)\nfrom ...utils import smart_tokenizer_and_embedding_resize\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nlogging.basicConfig(\n    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n    datefmt=\"%m/%d/%Y %H:%M:%S\",\n    handlers=[logging.StreamHandler(sys.stdout), ],\n)\nBox = List[Union[float, int]]\nBoxes = List[Box]\nBoxesSeq = List[Boxes]\n@FUNCTIONS.register_module()\nclass BoxFormatProcess(BaseTargetProcessFunc):\n    def __call__(self, raw_conv: List[Dict[str, Any]], target: Dict[str, Any], preprocessor: Dict[str, Any],\n                 multimage_mode=False) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:\n        box_formatter = preprocessor['target']['boxes']\n        if multimage_mode:\n            target = typing.cast(list, target)"
        },
        {
            "comment": "This code processes a dataset by normalizing the target boxes and points. It iterates over each target in the dataset and checks if 'boxes' key is present. If so, it appends normalized boxes and points to respective lists. Finally, it assigns these lists as normalized_boxes and normalized_points for further processing.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":39-61",
            "content": "            outer_normalized_boxes = []\n            for tgt in target:\n                normalized_boxes = []\n                if tgt is not None and 'boxes' in tgt:\n                    for box in tgt['boxes']:\n                        normalized_boxes.append(\n                            norm_box_xyxy(box, w=tgt['width'], h=tgt['height'])\n                        )\n                outer_normalized_boxes.append(normalized_boxes)\n            normalized_boxes = outer_normalized_boxes\n            outer_normalized_points = []\n            for tgt in target:\n                normalized_points = []\n                if tgt is not None and 'boxes' in tgt:\n                    for box in tgt['boxes']:\n                        normalized_points.append(\n                            norm_box_xyxy(box, w=tgt['width'], h=tgt['height'])\n                        )\n                outer_normalized_points.append(normalized_points)\n            normalized_points = outer_normalized_points\n        else:\n            # normalize target\n            normalized_boxes = []"
        },
        {
            "comment": "This code checks if 'boxes' and 'points' are present in the target. If they are, it normalizes them using specific functions with corresponding width and height values. The code then iterates over each sentence in raw_conv, extracts the box sequence associated with each sentence, asserts that there are no point placeholders, and maps the normalized boxes onto the box sequences.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":62-84",
            "content": "            if target is not None and 'boxes' in target:\n                for box in target['boxes']:\n                    normalized_boxes.append(\n                        norm_box_xyxy(box, w=target['width'], h=target['height'])\n                    )\n            normalized_points = []\n            if target is not None and 'points' in target:\n                for point in target['points']:\n                    normalized_points.append(\n                        norm_point_xyxy(point, w=target['width'], h=target['height'])\n                    )\n        # convert bboxes_seq\n        ret_all_boxes = []\n        ret_gpt_boxes = []\n        for sentence in raw_conv:\n            words: str = sentence['value']\n            boxes_seq: List[List[int]] = sentence.get('boxes_seq', None)\n            assert POINTS_PLACEHOLDER not in words # there should be no potints\n            if boxes_seq is not None:\n                # map box seq\n                boxes_seq: List[Boxes] = map_obj(normalized_boxes, boxes_seq)\n                # assert len(boxes_seq) == len([x for x in words.split() if x==BOXES_PLACEHOLDER])"
        },
        {
            "comment": "This code processes a dataset by replacing placeholders for boxes and points with actual box coordinates or point sequences. It also stores the original sentence value as 'raw_value' if any boxes or points are found.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":85-101",
            "content": "                # reformat; replace <boxes> placeholder\n                # converted = box_formatter(words, boxes_seq)\n                # words = converted\n                to_replace_strs = [\" \".join([BOXES_PLACEHOLDER]*len(seq)) for seq in boxes_seq]\n                words = words.replace(BOXES_PLACEHOLDER, \"{}\").format(*to_replace_strs)\n                ret_all_boxes.extend(flatten(boxes_seq))\n                if sentence[\"from\"] == \"gpt\":\n                    ret_gpt_boxes.extend(flatten(boxes_seq))\n            points_seq: List[List[int]] = sentence.get('points_seq', None)\n            if points_seq is not None:\n                # map point seq\n                points_seq: List[Boxes] = map_obj(normalized_points, points_seq)\n                # reformat; replace <points> placeholder\n                # converted = box_formatter.call_on_point(words, points_seq)\n                # words = converted\n            if boxes_seq is not None or points_seq is not None:\n                sentence['raw_value'] = sentence['value']"
        },
        {
            "comment": "The code defines a function `map_obj` that takes in a list of normalized boxes and box sequences. It flattens the normalized boxes into a single list and then maps each box sequence to its corresponding normalized box, creating a list of lists. The purpose is to create a representation that can be easily processed or analyzed further.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":102-129",
            "content": "                sentence['value'] = words\n        return raw_conv, dict(all_boxes=ret_all_boxes, gpt_boxes=ret_gpt_boxes)\ndef flatten(boxes: List[Boxes]):\n    return [b for a in boxes for b in a]\ndef map_obj(boxes_value: List[List[float]], boxes_seq: List[List[int]]) -> List[List[List[float]]]:\n    \"\"\"\n    >>> normalized_boxes = [[0.1, 0.1, 0.1, 0.1], [0.2, 0.2, 0.2, 0.2], [0.3, 0.3, 0.3, 0.3]]\n    >>> boxes_seq_ = [[3, 1], [2]]\n    >>> var = map_obj(normalized_boxes, boxes_seq_)\n    >>> assert var == [[[0.3,0.3,0.3,0.3], [0.1,0.1,0.1,0.1]], [0.2,0.2,0.2,0.2]]\n    \"\"\"\n    try:\n        ret = []\n        for boxes in boxes_seq:\n            boxes_ret = []\n            for box_index in boxes:\n                if isinstance(box_index, (list, tuple)):\n                    boxes_ret.append(boxes_value[box_index[0]][box_index[1]])\n                else:\n                    boxes_ret.append(boxes_value[box_index])\n            ret.append(boxes_ret)\n        return ret\n    except:\n        raise SystemExit(f\"error: map obj {boxes_value} {boxes_seq}\")"
        },
        {
            "comment": "The code defines a `BoxFormatter` class that initializes with bboxes and points tokens. It takes a sentence and a sequence of boxes, replaces the bbox token with formatted box strings, and returns the modified sentence. It also has a separate method to handle point sequences.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":132-151",
            "content": "class BoxFormatter:\n    def __init__(self, bboxes_token=BOXES_PLACEHOLDER, points_token=POINTS_PLACEHOLDER):\n        self.bboxes_token = bboxes_token\n        self.points_token = points_token\n        # normally the bboxes_token_pat is the same as bboxes_token if u not use some weird token\n        self.bboxes_token_pat = re.compile(bboxes_token)\n        self.points_token_pat = re.compile(points_token)\n    def __call__(self, sentence: str, bboxes_seq: BoxesSeq) -> str:\n        all_box = self.bboxes_token_pat.findall(sentence)\n        assert len(all_box) == len(bboxes_seq), f\"not match. sentence: {sentence}. boxes:{bboxes_seq}\"\n        if len(all_box) == 0:\n            return sentence\n        bboxes_strs = [self.format_box(bboxes) for bboxes in bboxes_seq]\n        converted = sentence.replace(self.bboxes_token, '{}').format(*bboxes_strs)\n        return converted\n    def call_on_point(self, sentence: str, points_seq: BoxesSeq) -> str:\n        all_box = self.points_token_pat.findall(sentence)\n        assert len(all_box) == len(points_seq), f\"not match. sentence: {sentence}. boxes:{points_seq}\""
        },
        {
            "comment": "This code defines a class for formatting and processing box data. The `BoxFormatter` class initializes with precision, use_small_brackets parameters, and uses regular expression patterns to match and format box data in the strings. It provides methods like `format_point`, `format_box`, `extract`, and `extract_point` which are not implemented yet, raising a NotImplementedError. The `PlainBoxFormatter` class extends `BoxFormatter` with additional initialization parameters.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":152-180",
            "content": "        if len(all_box) == 0:\n            return sentence\n        bboxes_strs = [self.format_point(bboxes) for bboxes in points_seq]\n        converted = sentence.replace(self.points_token, '{}').format(*bboxes_strs)\n        return converted\n    def format_point(self, points) -> str:\n        raise NotImplementedError\n    def format_box(self, bboxes: Boxes) -> str:\n        raise NotImplementedError\n    def extract(self, string: str) -> List[Boxes]:\n        raise NotImplementedError\n    def extract_point(self, string: str) -> List[Boxes]:\n        raise NotImplementedError\n@BOXES_PROCESSOR.register_module()\nclass PlainBoxFormatter(BoxFormatter):\n    def __init__(self, *args, precision=3, use_small_brackets=False, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.precision = precision\n        self.use_small_brackets = use_small_brackets\n        small_brackets_pat = re.compile(r'\\(\\d(?:\\.\\d*)?(?:,\\d(?:\\.\\d*)?){3}(?:;\\d(?:\\.\\d*)?(?:,\\d(?:\\.\\d*)?){3})*\\)')\n        small_brackets_point_pat = re.compile(r'\\(\\d(?:\\.\\d*)?(?:,\\d(?:\\.\\d*)?)(?:;\\d(?:\\.\\d*)?(?:,\\d(?:\\.\\d*)?))*\\)')"
        },
        {
            "comment": "This code defines a class with methods to format and extract bounding boxes from a given string. The class has a parameter that determines whether to use small or middle brackets for box formatting, and precision for floating point numbers within the boxes. It uses regular expressions to find occurrences of boxes in the input string, then formats them as needed before returning a list of those boxes.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":182-203",
            "content": "        middle_brackets_pat = re.compile(r'\\[\\d(?:\\.\\d*)?(?:,\\d(?:\\.\\d*)?){3}(?:;\\d(?:\\.\\d*)?(?:,\\d(?:\\.\\d*)?){3})*\\]')\n        middle_brackets_point_pat = re.compile(r'\\[\\d(?:\\.\\d*)?(?:,\\d(?:\\.\\d*)?)(?:;\\d(?:\\.\\d*)?(?:,\\d(?:\\.\\d*)?))*\\]')\n        self.pat = small_brackets_pat if use_small_brackets else middle_brackets_pat\n        self.point_pat = small_brackets_point_pat if use_small_brackets else middle_brackets_point_pat\n    def format_box(self, boxes: Boxes) -> str:\n        box_strs = []\n        for box in boxes:\n            box_strs.append(','.join([f\"{elem:.{self.precision}f}\" for elem in box]))\n        box_str = ';'.join(box_strs)\n        if self.use_small_brackets:\n            return \"(\" + box_str + \")\"\n        return \"[\" + box_str + \"]\"\n    def format_point(self, points) -> str:\n        return self.format_box(points)\n    def extract(self, string: str) -> List[Boxes]:\n        \"\"\" balabala<boxes>balabala<boxes> -> [boxes, boxes] \"\"\"\n        ret = []\n        for bboxes_str in self.pat.findall(string):"
        },
        {
            "comment": "This code defines a class called TokenFormatter, which inherits from BoxFormatter. It has two methods: box_process_function and extract_point. The box_process_function method processes bboxes by removing parentheses and brackets, splitting them into separate boxes, and converting the box coordinates to float values. The extract_point method finds occurrences of a specific pattern in a given string and extracts boxes from it using the box_process_function method. TokenFormatter is registered with BOXES_PROCESSOR for further usage.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":204-230",
            "content": "            bboxes = []\n            bbox_strs = bboxes_str.replace(\"(\", \"\").replace(\")\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\";\")\n            for bbox_str in bbox_strs:\n                bbox = list(map(float, bbox_str.split(',')))\n                bboxes.append(bbox)\n            ret.append(bboxes)\n        return ret\n    def extract_point(self, string: str) -> List[Boxes]:\n        \"\"\" balabala<boxes>balabala<boxes> -> [boxes, boxes] \"\"\"\n        ret = []\n        for bboxes_str in self.point_pat.findall(string):\n            bboxes = []\n            bbox_strs = bboxes_str.replace(\"(\", \"\").replace(\")\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\";\")\n            for bbox_str in bbox_strs:\n                bbox = list(map(float, bbox_str.split(',')))\n                bboxes.append(bbox)\n            ret.append(bboxes)\n        return ret\n@BOXES_PROCESSOR.register_module()\nclass TokenFormatter(BoxFormatter):\n    def __init__(self, num_bins=1001):\n        super().__init__()\n        self.extract_box_pat = re.compile(r'<b_st><bin_\\d*?>(?:<bin_\\d*?>){3}(?:<b_sep><bin_\\d*?>(?:<bin_\\d*?>){3})*<b_ed>')"
        },
        {
            "comment": "The code defines a class with a method `format_point` that takes a list of bounding boxes and formats them using regular expressions based on the number of bins, separator usage, and begin/end markers. The result is returned as a string representation of the formatted bounding boxes.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":231-256",
            "content": "        self.extract_point_pat = re.compile(r'<p_st><bin_\\d*?>(?:<bin_\\d*?>){1}(?:<p_sep><bin_\\d*?>(?:<bin_\\d*?>){1})*<p_ed>')\n        self.num_bins = num_bins\n        self.use_sep = True\n        self.use_begin_end = True\n        self.box_begin = '<b_st>'\n        self.box_sep = '<b_sep>'\n        self.box_end = '<b_ed>'\n        self.point_begin = '<p_st>'\n        self.point_sep = '<p_sep>'\n        self.point_end = '<p_ed>'\n    def format_point(self, points) -> str:\n        final_str = []\n        for bbox in points:\n            quant_x0 = \"<bin_{}>\".format(round((bbox[0] * (self.num_bins - 1))))\n            quant_y0 = \"<bin_{}>\".format(round((bbox[1] * (self.num_bins - 1))))\n            region_coord = \"{} {}\".format(quant_x0, quant_y0)\n            final_str.append(region_coord)\n        if self.use_sep:\n            final_str = self.point_sep.join(final_str)\n        else:\n            final_str = ''.join(final_str)\n        if self.use_begin_end:\n            final_str = self.point_begin + final_str + self.point_end"
        },
        {
            "comment": "The function `format_box` takes a set of bounding boxes and converts them into strings representing quantized x and y coordinates. The resulting strings are then joined together to form the final string. The `extract` function searches for the final string within another string, extracts it, and converts it back into a list of bounding boxes.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":257-280",
            "content": "        return final_str\n    def format_box(self, bboxes: Boxes) -> str:\n        final_str = []\n        for bbox in bboxes:\n            quant_x0 = \"<bin_{}>\".format(round((bbox[0] * (self.num_bins - 1))))\n            quant_y0 = \"<bin_{}>\".format(round((bbox[1] * (self.num_bins - 1))))\n            quant_x1 = \"<bin_{}>\".format(round((bbox[2] * (self.num_bins - 1))))\n            quant_y1 = \"<bin_{}>\".format(round((bbox[3] * (self.num_bins - 1))))\n            region_coord = \"{} {} {} {}\".format(quant_x0, quant_y0, quant_x1, quant_y1)\n            final_str.append(region_coord)\n        if self.use_sep:\n            final_str = self.box_sep.join(final_str)\n        else:\n            final_str = ''.join(final_str)\n        if self.use_begin_end:\n            final_str = self.box_begin + final_str + self.box_end\n        return final_str\n    def extract(self, string: str) -> List[Boxes]:\n        ret = []\n        for bboxes_str in self.extract_box_pat.findall(string.replace(\" \", \"\")):\n            bboxes = []\n            bbox_strs = bboxes_str.replace(self.box_begin, \"\").replace(self.box_end, \"\").split(self.box_sep)"
        },
        {
            "comment": "This code defines a class with methods to process box annotations for text data. The `box_process_function` method processes box annotations in the input string and returns a list of lists representing the box coordinates. The `extract_point` method extracts box annotations from the input string and returns a list of box coordinate lists. Lastly, the `post_process_model_tokenizer` method initializes a tokenizer for the model using the provided preprocessor.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":281-304",
            "content": "            for bbox_str in bbox_strs:\n                elems = list(map(int, re.findall(r'<bin_(\\d*?)>', bbox_str)))\n                bbox = [elem / (self.num_bins - 1) for elem in elems]\n                bboxes.append(bbox)\n            ret.append(bboxes)\n        return ret\n    def extract_point(self, string: str) -> List[Boxes]:\n        ret = []\n        for bboxes_str in self.extract_point_pat.findall(string):\n            bboxes = []\n            bbox_strs = bboxes_str.replace(self.point_begin, \"\").replace(self.point_end, \"\").split(self.point_sep)\n            for bbox_str in bbox_strs:\n                elems = list(map(int, re.findall(r'<bin_(\\d*?)>', bbox_str)))\n                bbox = [elem / (self.num_bins - 1) for elem in elems]\n                bboxes.append(bbox)\n            ret.append(bboxes)\n        return ret\n    def post_process_model_tokenizer(self, model, preprocessor, model_args, training_args):\n        tokenizer = preprocessor['text']\n        additional_special_tokens = [\n            self.box_begin, self.box_sep, self.box_end,"
        },
        {
            "comment": "This code adds additional special tokens to the model's tokenizer and resizes the embedding. It then checks if a target_processor is present in model arguments for boxes, builds a boxes_processor if it exists, and applies any necessary post-processing to the model's tokenizer.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":305-334",
            "content": "            self.point_begin, self.point_sep, self.point_end,\n        ]\n        for i in range(self.num_bins):\n            additional_special_tokens.append(f'<bin_{i}>')\n        smart_tokenizer_and_embedding_resize(\n            {'additional_special_tokens': additional_special_tokens},\n            tokenizer,\n            model,\n        )\n        return model, preprocessor\n# FIXME: merge into load_pretrained\ndef prepare_target_processor(\n        model,  # multimodal llm\n        preprocessor: Dict[str, Any],\n        model_args,\n        training_args,\n):\n    if not hasattr(model_args, 'target_processor'):\n        return model, preprocessor\n    target_processor = {}\n    if 'boxes' in model_args['target_processor']:\n        boxes_cfg = model_args['target_processor']['boxes']\n        boxes_processor = BOXES_PROCESSOR.build(boxes_cfg)\n        target_processor['boxes'] = boxes_processor\n        if hasattr(boxes_processor, \"post_process_model_tokenizer\"):\n            model, preprocessor = boxes_processor.post_process_model_tokenizer("
        },
        {
            "comment": "This function creates a model, preprocessor and returns both along with other arguments. The target processor is assigned to the preprocessor's 'target' attribute.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/mllm/dataset/process_function/box_process_function.py\":335-338",
            "content": "                model, preprocessor, model_args, training_args,\n            )\n    preprocessor['target'] = target_processor\n    return model, preprocessor"
        }
    ]
}