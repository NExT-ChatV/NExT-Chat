{
    "summary": "The code is launching a multi-process accelerated fine-tuning of an ML model (mllm/pipeline/finetune.py) using a specific configuration file (config/nextchat_eval_reg_cap.py). It sets the CUDA devices to use, the model's output directory, and the per-device evaluation batch size to 8. The main process port is set to 23787.",
    "details": [
        {
            "comment": "The code is launching a multi-process accelerated fine-tuning of an ML model (mllm/pipeline/finetune.py) using a specific configuration file (config/nextchat_eval_reg_cap.py). It sets the CUDA devices to use, the model's output directory, and the per-device evaluation batch size to 8. The main process port is set to 23787.",
            "location": "\"/media/root/Prima/works/NExT-Chat/docs/src/eval_reg_cap.sh\":0-7",
            "content": "MODEL_PATH=$1\nCUDA_VISIBLE_DEVICES=\"0,1,2,3,4,5,6,7\" accelerate launch --num_processes 1 \\\n        --main_process_port 23787 \\\n        mllm/pipeline/finetune.py \\\n        config/nextchat_eval_reg_cap.py \\\n        --cfg-options model_args.model_name_or_path=$MODEL_PATH model_args.mm_projector_depth=2 \\\n        --output_dir \"$MODEL_PATH\"/reg_cap/  --per_device_eval_batch_size 8"
        }
    ]
}