{"_default": {"1": {"path": "/DATA.md", "hash": "74ee70501e43887b049f462f794fd85d", "title": "Downloading and Organizing Shikra Data Files"}, "2": {"path": "/DATA.md:1-20", "hash": "13138860a54def2ddf78e41bbb2bd9ff", "title": "Download and Organize Shikra Data Files"}, "3": {"path": "/DATA.md:20-40", "hash": "6d691a2581bd85ffefc3f7ed55933728", "title": "Flickr30k Trainset Location"}, "4": {"path": "/README.md", "hash": "ecf699b6a2991d63c14f881441dfd636", "title": "NextChat: Enhanced Image-Based Text Generation"}, "5": {"path": "/README.md:1-26", "hash": "f8bd19349809bce5144a972eaed43e84", "title": "Language Modeling and Machine Learning Chatbot"}, "6": {"path": "/README.md:27-58", "hash": "94ded6beeaa4a4e99c808f6b0fb1cf99", "title": "NExT-Chat: LMM for Chat Models"}, "7": {"path": "/README.md:60-89", "hash": "a5ac7aee801ac5c796f179f9cf551a84", "title": "Updated and Streamlined Model Templates"}, "8": {"path": "/README.md:90-107", "hash": "e75f15bb00b3f1e8e7de545caffb0747", "title": "Install and Run Demos with Pre-Trained Models"}, "9": {"path": "/README.md:108-134", "hash": "71d4b1004376f3704f5c567c97d633af", "title": "Generate Text from Image with NextChat Model"}, "10": {"path": "/README.md:135-157", "hash": "98476e5638e5f63d05a876f7901a7460", "title": "Model Evaluation Results & Configuration Instructions"}, "11": {"path": "/README.md:158-176", "hash": "45c50c9a8c601ad4bbf1e2462f55ccef", "title": "Optimizing REC Performance: Balancing Losses and Pope"}, "12": {"path": "/README.md:176-189", "hash": "5d6857e43421454e8ede663eda10cd74", "title": "Configure Vision Tower with SAM Model"}, "13": {"path": "/README.md:189-211", "hash": "60a6372e607196de0b1cf92a0f428298", "title": "Training Stages and Scripts: VL+Detection"}, "14": {"path": "/README.md:212-243", "hash": "7b00525931efee37941831d2e2b43683", "title": "Nextchat-13b Model Showcase"}, "15": {"path": "/config/_base_/model/nextchat.py", "hash": "2d802569fc14fd297a751191dea01f9d", "title": "Configuring NextChat Model"}, "16": {"path": "/config/_base_/model/nextchat.py:1-42", "hash": "bd2c1d3ea34465789a2b065cc5806fb1", "title": "NextChat Model Configuration"}, "17": {"path": "/config/_base_/model/nextchat.py:43-48", "hash": "dda671a5dacf0f471a7bc295536ac068", "title": "NextChat Model Customization"}, "18": {"path": "/config/_base_/train/eval.py", "hash": "db8c272d5028868e0b8ec570c7ace730", "title": "Training Arguments Dictionary"}, "19": {"path": "/config/_base_/train/nextchat_fsdp.py", "hash": "865060b77a314f5632313f849d762cf2", "title": "Training Arguments for Deep Learning Model"}, "20": {"path": "/config/_base_/train/nextchat_non.py", "hash": "5a873ba10aa0aac43e12453aaf49a990", "title": "Training Arguments for ML Model"}, "21": {"path": "/config/nextchat_eval_multi_rec.py", "hash": "aeff9c9c6ed07fa4c8af839aa1ab88ce", "title": "Multi-Predict NextChat Evaluation"}, "22": {"path": "/config/nextchat_eval_multi_res.py", "hash": "8ce0e1557bc7af407634209c79b15c93", "title": "Multi-Res Nextchat Evaluation"}, "23": {"path": "/config/nextchat_eval_multi_res.py:1-45", "hash": "6ee9e21182db499f11d40801531cf15a", "title": "Multi-res Nextchat Evaluation Config"}, "24": {"path": "/config/nextchat_eval_multi_res.py:46-48", "hash": "8a410861732d7de0a40cb42d1addc48e", "title": "Single Beam Search Evaluation"}, "25": {"path": "/config/nextchat_eval_pope.py", "hash": "8bcc7a69f64b3e8727834db663c7a7c8", "title": "NextChat Evaluation Configs"}, "26": {"path": "/config/nextchat_eval_reg_cap.py", "hash": "a9a3e69aa599af4d6e1fb73dcf5df461", "title": "NextChat Evaluation Config"}, "27": {"path": "/config/nextchat_stage1.py", "hash": "afd606f341836566de9d1b2509ca7386", "title": "Initializing NextChat Stage 1 Model"}, "28": {"path": "/config/nextchat_stage2.py", "hash": "7943e3c21824f1a8343c921af9520522", "title": "Training NextChat Stage 2 Model"}, "29": {"path": "/config/nextchat_stage3.py", "hash": "5ee8c1d1f4abd168f03f2eb1e08f5daa", "title": "NextChat Stage 3 Config"}, "30": {"path": "/eval_pope.sh", "hash": "70a87f33ee510f3164a02e56fb96db6a", "title": "Accelerated Finetuning with CUDA"}, "31": {"path": "/eval_rec.sh", "hash": "c982c242334bf4c02314677288fcc584", "title": "Finetune Multimodal Model with Accelerate"}, "32": {"path": "/eval_reg_cap.sh", "hash": "47450bb731582a2b803d33febbc07fc3", "title": "Multi-Process ML Acceleration"}, "33": {"path": "/eval_res.sh", "hash": "1162771e57572be8fac46c5182329064", "title": "Accelerate Library Launch: Multi-Device Evaluation"}, "34": {"path": "/mllm/config/__init__.py", "hash": "db35f94a9b2bdc676144ac05ecf27de2", "title": "Imports Prepare Args Function"}, "35": {"path": "/mllm/config/config.py", "hash": "3177a7a58b24ccce096bf3adb1f8a214", "title": "Setup and Config Management"}, "36": {"path": "/mllm/config/config.py:1-32", "hash": "f0484d62f4d230d158b813c55c8ffa99", "title": "Seq2SeqTrainingArgs Preparation"}, "37": {"path": "/mllm/config/config.py:33-52", "hash": "3596c483f3e48ea0fced0700128704ae", "title": "Config Override with ArgumentParsers"}, "38": {"path": "/mllm/config/config.py:54-82", "hash": "659601e76242e39a989581345e962e55", "title": "Config Processing and Initialization"}, "39": {"path": "/mllm/config/config.py:83-106", "hash": "093ca5a1b8bd1084b67ca30486ef8050", "title": "Configuring Logger Settings"}, "40": {"path": "/mllm/config/config.py:107-128", "hash": "b354bd5fc79b412c589609b1125344d1", "title": "Checkpoint Resumption and Output Directory Management"}, "41": {"path": "/mllm/config/config.py:129-135", "hash": "07725ec8b2b3bbba63651ce36205288a", "title": "Check Output Directory Flag"}, "42": {"path": "/mllm/conversation/__init__.py", "hash": "f485ac254b5198d438616eeb399d8d4c", "title": "Initializing Conversation Module"}, "43": {"path": "/mllm/conversation/base_conversation.py", "hash": "851d4af953e2d8cbc5d0a094ecf12828", "title": "Renewable Energy Chatbot Framework"}, "44": {"path": "/mllm/conversation/base_conversation.py:1-47", "hash": "9ba635dbf8d1ca3ccc98435d5bdac5c1", "title": "Conversation History Class"}, "45": {"path": "/mllm/conversation/base_conversation.py:49-75", "hash": "aab6acc96f7e78121d34b87c040c6539", "title": "Python Conversation Class: Generating Prompts"}, "46": {"path": "/mllm/conversation/base_conversation.py:76-102", "hash": "b48747c37c42cfaa2102810bc0ecea35", "title": "Versatile Conversation Styler"}, "47": {"path": "/mllm/conversation/base_conversation.py:103-129", "hash": "bf1c31c60f16ee92df591c9fca72fe86", "title": "Conversation Formatter for Separator Styles"}, "48": {"path": "/mllm/conversation/base_conversation.py:130-157", "hash": "b3e718224cac8369a2f03c54f00ea1e7", "title": "Conversation History Generator in Different Styles"}, "49": {"path": "/mllm/conversation/base_conversation.py:158-188", "hash": "d541265d2279895379a31f2b22dfd08f", "title": "Conversation Class and Formats"}, "50": {"path": "/mllm/conversation/base_conversation.py:189-224", "hash": "5042a78aaff5c43506b4633846e7ecb2", "title": "Conversation Class with Templates"}, "51": {"path": "/mllm/conversation/base_conversation.py:225-241", "hash": "37e0bfc5009c0dc8a9c9ec066b521c14", "title": "Renewable vs Non-Renewable Energy: A Conversation"}, "52": {"path": "/mllm/conversation/base_conversation.py:242-254", "hash": "f9cd9a0c262821ab3f2da6e0166cabb9", "title": "Renewable Energy Advantages: Sustainability and Cost Savings"}, "53": {"path": "/mllm/conversation/base_conversation.py:255-294", "hash": "cd65b0af91a003efd79f201502cc1f13", "title": "Chat Templates Registration"}, "54": {"path": "/mllm/conversation/base_conversation.py:295-325", "hash": "3f45755896ecd31ae8e8b941f06f5833", "title": "Multi-Template Conversation Registration"}, "55": {"path": "/mllm/conversation/base_conversation.py:326-342", "hash": "8fbaa26b38e437a56848ea54a9e65aba", "title": "Conversation Object: Baize Template"}, "56": {"path": "/mllm/conversation/base_conversation.py:343-378", "hash": "1a66bc840a6f3b45dd7216844f20af42", "title": "Registering Conversation Templates for NExT-Chat"}, "57": {"path": "/mllm/conversation/base_conversation.py:379-404", "hash": "90c0e15ff497ee56433798ca462ac611", "title": "Creative Conversational AI Base Class"}, "58": {"path": "/mllm/conversation/base_conversation.py:405-445", "hash": "ae5968bfcc90216e3f22d69d86c4adb3", "title": "Default Templates for AI Conversation Models"}, "59": {"path": "/mllm/conversation/base_conversation.py:446-487", "hash": "d969a8f9056bbcf1f9708e2ff48a5438", "title": "Registering Conversation Templates"}, "60": {"path": "/mllm/conversation/base_conversation.py:488-503", "hash": "5ac67a5f922c4838f032629f64b0575f", "title": "Conversation Template Initialization"}, "61": {"path": "/mllm/dataset/__init__.py", "hash": "53692c9cedde8fef73ace2094382f959", "title": "Consolidated Dataset Manager"}, "62": {"path": "/mllm/dataset/builder.py", "hash": "7a7a5d54620f7fa173cdce6b03e87c66", "title": "NExT-Chat Data Builder"}, "63": {"path": "/mllm/dataset/builder.py:1-27", "hash": "847463c6f7c4344463526226eac8b870", "title": "MLLM Dataset Builder"}, "64": {"path": "/mllm/dataset/builder.py:28-53", "hash": "c919f273d47b42f2feb46fc6fe13c688", "title": "Dataset Builder and Wrapper Class"}, "65": {"path": "/mllm/dataset/builder.py:54-70", "hash": "198dedfd78742f4702ca59d390f5c1ba", "title": "Multi-Test Dataset Builder"}, "66": {"path": "/mllm/dataset/builder.py:71-100", "hash": "6c4caa86b872127214c523ca31e88a0d", "title": "Interactive Ceph Client Dataset Builder"}, "67": {"path": "/mllm/dataset/builder.py:101-118", "hash": "229604174d4f9791fc3e419336fe2637", "title": "Next-Chat Dataset Builder"}, "68": {"path": "/mllm/dataset/process_function/__init__.py", "hash": "99790829eeaf608ee54752667517472f", "title": "Multimodal Process Functions"}, "69": {"path": "/mllm/dataset/process_function/box_process_function.py", "hash": "71995ec9490dd63c3ce8111a525031e7", "title": "Unified Box Format Normalization"}, "70": {"path": "/mllm/dataset/process_function/box_process_function.py:1-39", "hash": "c9d82c58e09ef0c92e16ce8bcacbc534", "title": "Box Format Normalization Function"}, "71": {"path": "/mllm/dataset/process_function/box_process_function.py:40-62", "hash": "aac4b79775a26711d8ffb44c7a74d252", "title": "Normalizing Boxes and Points in Dataset Processing"}, "72": {"path": "/mllm/dataset/process_function/box_process_function.py:63-85", "hash": "f788625d24122f907339cb598694114f", "title": "Box-Point Normalization Process"}, "73": {"path": "/mllm/dataset/process_function/box_process_function.py:86-102", "hash": "aad03618f2b18e6bdc5faf96ad06d5af", "title": "Dataset Box and Point Processing"}, "74": {"path": "/mllm/dataset/process_function/box_process_function.py:103-130", "hash": "eaaa8aa439b9045ac72ed68b8104feac", "title": "Flattening Boxes and Mapping Sequences"}, "75": {"path": "/mllm/dataset/process_function/box_process_function.py:133-152", "hash": "009d09266a43e41a88749d41bbbef301", "title": "Box Formatter Class"}, "76": {"path": "/mllm/dataset/process_function/box_process_function.py:153-181", "hash": "5ddef5403bd84c140b197f38062da17f", "title": "Box Data Formatter and Processor"}, "77": {"path": "/mllm/dataset/process_function/box_process_function.py:183-204", "hash": "e34dabf1ce42304a6cb21a865bda5a3d", "title": "Box Formatter and Extractor Class"}, "78": {"path": "/mllm/dataset/process_function/box_process_function.py:205-231", "hash": "aedf7e44279cf6b3f8ea59ae1a29fcbf", "title": "Box Processor Function: TokenFormatter"}, "79": {"path": "/mllm/dataset/process_function/box_process_function.py:232-257", "hash": "ccd5c725f7ca89e92e508c07e61546d7", "title": "Bounding Box Formatter"}, "80": {"path": "/mllm/dataset/process_function/box_process_function.py:258-281", "hash": "8481b38885d5201267dc3853ccd7720a", "title": "Box Quantization and Extraction Functions"}, "81": {"path": "/mllm/dataset/process_function/box_process_function.py:282-305", "hash": "5b60335fb96bcf3a8e54f269b285f4d7", "title": "Box Annotations Processing Class"}, "82": {"path": "/mllm/dataset/process_function/box_process_function.py:306-335", "hash": "3041ccd0f89d1e96bfb65fa893710938", "title": "Resizing Embeddings and Processing Boxes"}, "83": {"path": "/mllm/dataset/process_function/box_process_function.py:336-339", "hash": "d05129f0c5661976cefad2533da615b6", "title": "Model-Preprocessor Creation Function"}, "84": {"path": "/mllm/dataset/process_function/chat_process_function.py", "hash": "d24bb70edb16b2874be268accb4aa087", "title": "Chat Tokenizer Process Function"}, "85": {"path": "/mllm/dataset/process_function/chat_process_function.py:1-40", "hash": "61798b6906772e969eb952837302324c", "title": "Chat Processing Function in Python"}, "86": {"path": "/mllm/dataset/process_function/chat_process_function.py:41-57", "hash": "e4ff88e8e7f794623cb13a11ae00b088", "title": "Image Token Handling in Chat Process"}, "87": {"path": "/mllm/dataset/process_function/chat_process_function.py:58-83", "hash": "e78ca0d9c383997127a760fefa9e3458", "title": "Chat Conversation Tokenizer"}, "88": {"path": "/mllm/dataset/process_function/chat_process_function.py:84-104", "hash": "25e95225d1fe211cb515d58dfc4d31d5", "title": "Truncate Text: Retain Image Tokens"}, "89": {"path": "/mllm/dataset/process_function/chat_process_function.py:105-127", "hash": "f87006bb9fdc9d5dd15feb95fab6933f", "title": "Truncate and Mask Target Tokens"}, "90": {"path": "/mllm/dataset/process_function/chat_process_function.py:128-152", "hash": "9be987b30cfbc6fe80a90bfa1ec72100", "title": "Chat Tokenizer and Input Processing"}, "91": {"path": "/mllm/dataset/process_function/chat_process_function.py:154-176", "hash": "2c54510ccc592f34b650eb1da840f669", "title": "Image Processing for ML Models"}, "92": {"path": "/mllm/dataset/process_function/chat_process_function.py:177-180", "hash": "cf00ef99f3a3be161ad4da555c1dc3ee", "title": "ValueError-Triggered Zero Image Creation"}, "93": {"path": "/mllm/dataset/root.py", "hash": "ae7bde00cbefeeb0ba7bed72bfffcb59", "title": "Python Conversation Data Processor Classes"}, "94": {"path": "/mllm/dataset/root.py:1-40", "hash": "53644960e8d0b4da36c18f12c5551cfe", "title": "Chat Data Processor Functions"}, "95": {"path": "/mllm/dataset/root.py:41-68", "hash": "413e263a4095f249d19af30a0709adb4", "title": "Abstract Base Classes for ML Dataset Functions"}, "96": {"path": "/mllm/dataset/single_image_convsation.py", "hash": "e08383abf4859ff16c70d124a8544547", "title": "Single Image Conv Dataset Mixin"}, "97": {"path": "/mllm/dataset/single_image_convsation.py:1-33", "hash": "36bc4926c59eabb11f8518fa4bd14ec3", "title": "Single Image Conversation Dataset Class"}, "98": {"path": "/mllm/dataset/single_image_convsation.py:34-56", "hash": "70f2560cc936240e65313adb58ac2823", "title": "Class Initializing Attributes for Single Image Conversation"}, "99": {"path": "/mllm/dataset/single_image_convsation.py:57-74", "hash": "e742b6123918f44ea26b5f1267f9ff61", "title": "Image and Target Transformations"}, "100": {"path": "/mllm/dataset/single_image_convsation.py:75-104", "hash": "3b84bce5a7e01d1be2aa1c2e7e11d6f7", "title": "Image-Assisted Conversation Processing"}, "101": {"path": "/mllm/dataset/single_image_convsation.py:105-133", "hash": "25b109c476d1c0934a07e9eb879fa604", "title": "Single Image Conversation Extraction"}, "102": {"path": "/mllm/dataset/single_image_convsation.py:134-156", "hash": "007465c70aa23181fc3dec668d5e1ad6", "title": "Validate Raw Items: Single Image Conversation Dataset"}, "103": {"path": "/mllm/dataset/single_image_convsation.py:157-179", "hash": "78de0e6c04fbf2ed3a7fb68def5e231c", "title": "Verifying Image and Boxes Placeholders in GPT Conversations"}, "104": {"path": "/mllm/dataset/single_image_convsation.py:180-200", "hash": "da2cfc1ed5da2605c79a527a242080a2", "title": "Preprocessing Conversations for ML Models"}, "105": {"path": "/mllm/dataset/single_image_convsation.py:201-218", "hash": "addcfa7312149044d88f364ff4c12251", "title": "Image and Text Processing Methods"}, "106": {"path": "/mllm/dataset/single_image_convsation.py:219-238", "hash": "bcd0a9d7bec34577eaa2399c70c1fedb", "title": "Check and Save Image Data"}, "107": {"path": "/mllm/dataset/single_image_convsation.py:239-260", "hash": "725aac3d881eb760250562bff78d2a71", "title": "SingleImageConvDataset Initialization"}, "108": {"path": "/mllm/dataset/single_image_convsation.py:261-290", "hash": "61950b6150863ae6c312b59bc23531ad", "title": "SingleImageConvSegDataset Class"}, "109": {"path": "/mllm/dataset/single_image_convsation.py:291-316", "hash": "f4ab7c8f5dce12e8bab9326a17bacaf5", "title": "Lazy Dataset Class for Big Python Objects"}, "110": {"path": "/mllm/dataset/single_image_convsation.py:317-342", "hash": "0cf012d36a3849d44e48666a503150a9", "title": "Dataset Representation and Retrieval"}, "111": {"path": "/mllm/dataset/single_image_convsation.py:343-362", "hash": "303bb4361a37aa0f39198bec84c76b0f", "title": "Image Preprocessing for Conversations"}, "112": {"path": "/mllm/dataset/single_image_convsation.py:363-388", "hash": "f7423f332ae4c80a81c958ab07a087d9", "title": "Multi-Image Conversation Classifier"}, "113": {"path": "/mllm/dataset/single_image_convsation.py:389-392", "hash": "73f60cafdc4e07d8d3c52928be6514b6", "title": "Single Image Conversation Datasets"}, "114": {"path": "/mllm/dataset/single_image_interactive.py", "hash": "3d8ae759dec0c058e87c6fa27577af9b", "title": "Single Image Dataset Class for Chat Apps"}, "115": {"path": "/mllm/dataset/single_image_interactive.py:1-33", "hash": "41b29d5fc9a10881b8365cf25bf5d9b8", "title": "Interactive Single Image Dataset Class"}, "116": {"path": "/mllm/dataset/single_image_interactive.py:34-58", "hash": "ec8e60dd48f4ccf375194461c34ba1f3", "title": "Object Index Conversion and Image Modification"}, "117": {"path": "/mllm/dataset/single_image_interactive.py:59-91", "hash": "e48b68928c02a92bff062009f95f792f", "title": "Interactive Image Chatbot Dataset: Classes & Methods"}, "118": {"path": "/mllm/dataset/single_image_interactive.py:92-118", "hash": "59b8ad66c901e1e53d005b80afef349c", "title": "Single Image Interactive Dataset Processing"}, "119": {"path": "/mllm/dataset/single_image_interactive.py:119-148", "hash": "3e50e9f4cf8d5ab72a34013b338c9a00", "title": "Single Image Interactive List Manager"}, "120": {"path": "/mllm/dataset/single_image_interactive.py:149-168", "hash": "75f48feebfc5c0a8dff944384a067ef2", "title": "Single Image Dataset Preprocessing"}, "121": {"path": "/mllm/dataset/single_image_interactive.py:169-188", "hash": "63a2f23e22ef9b135242aa3e89a3e1ff", "title": "Conversation Data Processing and Output"}, "122": {"path": "/mllm/dataset/utils/__init__.py", "hash": "32dc0d705c9397c57aa73a969f6f4865", "title": "Utility Functions for ML Dataset"}, "123": {"path": "/mllm/dataset/utils/compute_metrics.py", "hash": "ba7ff166b3056797570487fc85e3b699", "title": "Compute Metrics for Transformer Models"}, "124": {"path": "/mllm/dataset/utils/compute_metrics.py:1-31", "hash": "8dff5bba42df20ab8c01f7a591a91c69", "title": "Compute Metrics Class for Transformers"}, "125": {"path": "/mllm/dataset/utils/compute_metrics.py:32-53", "hash": "bb8f9a2d6c49c8cf9dbaf8adddc19ac0", "title": "Compute Metrics for ML Model"}, "126": {"path": "/mllm/dataset/utils/concatenate_dataset.py", "hash": "241c3929efe710661a54a7871dd2ad23", "title": "Interleaved Concat Datasets with Probabilities"}, "127": {"path": "/mllm/dataset/utils/concatenate_dataset.py:1-34", "hash": "40fa902a19b3c8b9a904d4bfc37aea83", "title": "Concatenate PyTorch Datasets"}, "128": {"path": "/mllm/dataset/utils/concatenate_dataset.py:35-70", "hash": "9bba2e8cc822f4bc8d024a938c489317", "title": "Interleaved Dataset Builder"}, "129": {"path": "/mllm/dataset/utils/concatenate_dataset.py:71-94", "hash": "a18c1bd531896d7e2f89b39218ff2d9b", "title": "Concatenate Dataset Representation"}, "130": {"path": "/mllm/dataset/utils/concatenate_dataset.py:95-111", "hash": "d76f2f90883af80a21f24d8e75523567", "title": "Interleaved Undersampling"}, "131": {"path": "/mllm/dataset/utils/concatenate_dataset.py:111-125", "hash": "14cd899e671a464dcbd24429c5a0b222", "title": "Handling Dataset Concatenation Scenarios"}, "132": {"path": "/mllm/dataset/utils/concatenate_dataset.py:126-143", "hash": "4a8da6ea9493d1a7560a3a11c81d0ac3", "title": "Random Indices Iterator"}, "133": {"path": "/mllm/dataset/utils/concatenate_dataset.py:144-168", "hash": "8eaf584b9730aee0dda9398880645533", "title": "SubSet Class for Data Slicing"}, "134": {"path": "/mllm/dataset/utils/concatenate_dataset.py:169-192", "hash": "e6f30ffea14fb9042b927baf11148500", "title": "Concatenate and Shuffle Datasets"}, "135": {"path": "/mllm/dataset/utils/flickr30k_entities_utils.py", "hash": "6e5f93fcecb6f1457281f198812c8cd7", "title": "Efficient Flickr30k Entities Data Processing"}, "136": {"path": "/mllm/dataset/utils/flickr30k_entities_utils.py:1-33", "hash": "1ecdb1034f865e7c1c10f23c85765a52", "title": "Flickr30K Entities Parser"}, "137": {"path": "/mllm/dataset/utils/flickr30k_entities_utils.py:34-66", "hash": "1a6267336a363cb85b3d3494fda49701", "title": "Flickr30K Entity Extractor"}, "138": {"path": "/mllm/dataset/utils/flickr30k_entities_utils.py:67-93", "hash": "48aa245c2b28e91b9ead32f393008c73", "title": "Flickr30K Entities Extraction Utility"}, "139": {"path": "/mllm/dataset/utils/flickr30k_entities_utils.py:94-115", "hash": "02247b604071981900f572c24cc02383", "title": "XML Parser: Extracting Objects, Boxes, and Nobox Labels"}, "140": {"path": "/mllm/dataset/utils/flickr30k_entities_utils.py:116-153", "hash": "94a33373795dc11242e65cde13ce82c6", "title": "Flatten Annotations with XML and Text Data"}, "141": {"path": "/mllm/dataset/utils/flickr30k_entities_utils.py:153-175", "hash": "9568da40b05cfe1df07f882baffc85ec", "title": "Box Sequences for Phrases"}, "142": {"path": "/mllm/dataset/utils/flickr30k_entities_utils.py:176-200", "hash": "abbf370eb6d4d2f82ef9d50229a5568c", "title": "Flickr30k Entities Processing Utilities"}, "143": {"path": "/mllm/dataset/utils/flickr30k_entities_utils.py:201-205", "hash": "45cdfd8f6a3e3b37ebfc950d1e09c8eb", "title": "Read and Process Filenames"}, "144": {"path": "/mllm/dataset/utils/io.py", "hash": "c1f9141c07bc71d750f30d40607dcfee", "title": "S3 Image Reader: Efficient Handling and Exception Control"}, "145": {"path": "/mllm/dataset/utils/io.py:1-40", "hash": "e5d325a36aa1797528ae2270bf98e8e5", "title": "Read Image: S3 or Local"}, "146": {"path": "/mllm/dataset/utils/io.py:41-54", "hash": "98f9bc71b92be32f7d85a6776d81d9e0", "title": "Ceph Client Initialization Logger"}, "147": {"path": "/mllm/dataset/utils/mixin.py", "hash": "f12e5254e0589c5c0bb310ec2563580a", "title": "Mixin-Based Dataset Creation"}, "148": {"path": "/mllm/dataset/utils/mixin.py:1-32", "hash": "7a1bef33de4dd30b01e109a20051b641", "title": "Question Template Mixin Class"}, "149": {"path": "/mllm/dataset/utils/mixin.py:33-62", "hash": "7bc54705691349169e1a6cd45307e715", "title": "Implementing MInstrDataset Class"}, "150": {"path": "/mllm/dataset/utils/mixin.py:63-96", "hash": "8ad9a7901d9f1e441c3b34f21852b8ea", "title": "Dataset Mixin Class"}, "151": {"path": "/mllm/dataset/utils/mixin.py:97-98", "hash": "cc058a6f404c7db65e2774036458b0a9", "title": "Empty String Representation"}, "152": {"path": "/mllm/dataset/utils/transform.py", "hash": "9a258dc3d25b1c55940cef8e199eb5f5", "title": "Versatile Image Transforms for NExT-Chat Dataset"}, "153": {"path": "/mllm/dataset/utils/transform.py:1-50", "hash": "0b266ba7be066f59ef302ef8fd332949", "title": "Image and Bounding Box Coordinate Transformations"}, "154": {"path": "/mllm/dataset/utils/transform.py:51-83", "hash": "52dea9e7674948e5e5a0b8bcd58b0016", "title": "Image Transform Utilities"}, "155": {"path": "/mllm/dataset/utils/transform.py:84-116", "hash": "f54ccdfe262a9a601233545cdba66718", "title": "Expand Image to Square"}, "156": {"path": "/mllm/dataset/utils/transform.py:117-146", "hash": "10469fad2d0a775c98cae1ad8fb76118", "title": "Bounding Box Transformation and Crop"}, "157": {"path": "/mllm/dataset/utils/transform.py:147-175", "hash": "cd5bd4d3ba74755c275587fadd13b811", "title": "Image Transform Utility"}, "158": {"path": "/mllm/dataset/utils/transform.py:177-209", "hash": "c9db7fc7bb6955243446afc197fa9510", "title": "Flip and Resize Image"}, "159": {"path": "/mllm/dataset/utils/transform.py:210-243", "hash": "500804a6184f4f7d1c0bf97d7b591958", "title": "Resizable Image with Maintained Aspect Ratio"}, "160": {"path": "/mllm/dataset/utils/transform.py:244-274", "hash": "2de820f2295f166d87be3ea26148fd52", "title": "Image Resizing and Cropping Utility"}, "161": {"path": "/mllm/dataset/utils/transform.py:275-309", "hash": "5c91ddad2f4f59298a57562c3f32d257", "title": "Random Image Transformations"}, "162": {"path": "/mllm/dataset/utils/transform.py:310-343", "hash": "28c9e011a45f6179f8018c40c381c521", "title": "Train Augmentation Class for Images"}, "163": {"path": "/mllm/dataset/utils/transform.py:344-363", "hash": "4128f09b711c5de567b9d055bb45e7d3", "title": "Custom Image Transformations"}, "164": {"path": "/mllm/dataset/utils/transform.py:364-365", "hash": "e78b6ca38d91e2c5ac2e7785adf57ccd", "title": "Add Points Label to Image"}, "165": {"path": "/mllm/demo/bash_demo.py", "hash": "f1e1e3b1c681b7a063f81bd0e4fe8b95", "title": "NextChat Inference Demo"}, "166": {"path": "/mllm/demo/demo_util.py", "hash": "1c4df13fd80ac4bd18280d3054a43bc1", "title": "Image-Enhanced AI Chat System with ML-LM"}, "167": {"path": "/mllm/demo/demo_util.py:1-38", "hash": "68fcb025e82044e5f134774bedbc4c8b", "title": "ML-LM Demo Setup"}, "168": {"path": "/mllm/demo/demo_util.py:39-74", "hash": "2289572b1dbf6dff5b6ce3d1b36753d1", "title": "Customizable ML Model Builder"}, "169": {"path": "/mllm/demo/demo_util.py:75-109", "hash": "81218ab32b75b7e76eff84e3141f85d3", "title": "Loading and Configuring NextChat Model"}, "170": {"path": "/mllm/demo/demo_util.py:110-131", "hash": "6a079e402696638e2c05715130fa3b1d", "title": "Preparing Preprocessor for LLM and Vision Models"}, "171": {"path": "/mllm/demo/demo_util.py:132-171", "hash": "d414c27ef2d29fd2238ebb4e3e344bd2", "title": "Image Resizing and Expansion Utilities"}, "172": {"path": "/mllm/demo/demo_util.py:172-208", "hash": "3b3feb5100f3f4cb257040cf1f7203fe", "title": "Image Processing Library for Object Detection"}, "173": {"path": "/mllm/demo/demo_util.py:209-244", "hash": "1c33d0962cf22b18775d4df5db5c93f0", "title": "Mask and Bounding Box Manipulation Functions"}, "174": {"path": "/mllm/demo/demo_util.py:245-267", "hash": "a1eceda06aabc6c5214fcb1f2a12a837", "title": "Adding Text to Images with Bounding Boxes"}, "175": {"path": "/mllm/demo/demo_util.py:268-292", "hash": "95196b9311c05fd9b849539ab13698d0", "title": "Interactive Image Grounding with ML"}, "176": {"path": "/mllm/demo/demo_util.py:293-318", "hash": "fe93099bb9b66bd9a946c8d8a4957cc5", "title": "AI Chat Image Processing Demo"}, "177": {"path": "/mllm/demo/demo_util.py:318-335", "hash": "6fec3a9c1f21d01ba822ff696f25580f", "title": "Image-Guided Text Generation Model"}, "178": {"path": "/mllm/demo/demo_util.py:336-337", "hash": "24a14268e064df189f883da6de5b9a4f", "title": "Image Classification Responses: Bounding Boxes, Masks, Retouched"}, "179": {"path": "/mllm/demo/web_demo.py", "hash": "00b7e865f5fc2bfa74825a4b27dbb12b", "title": "Interactive Image Chatbot with GR Library"}, "180": {"path": "/mllm/demo/web_demo.py:1-32", "hash": "30d9e44910d7654805bf2e8605f2b04a", "title": "Web Demo: Initializing NExT-Chat Model"}, "181": {"path": "/mllm/demo/web_demo.py:33-67", "hash": "188c2411897363b82d1f8bceb8c41aa4", "title": "NextChatInference Initialization and Chat Function"}, "182": {"path": "/mllm/demo/web_demo.py:68-97", "hash": "0cb38833a832725048279cfc49df9315", "title": "Image-Recognizing Chatbot"}, "183": {"path": "/mllm/demo/web_demo.py:98-130", "hash": "289aa4681be0d0647d501a00ea6fc750", "title": "Initializing GROMACS Block for NExT-Chat"}, "184": {"path": "/mllm/demo/web_demo.py:131-151", "hash": "df681db1754cb11785f7d457c93ef53b", "title": "Region-Based Prompting for Improved LLMs"}, "185": {"path": "/mllm/demo/web_demo.py:152-171", "hash": "5a42b4042f7b03d2a97bb4fedec25e2a", "title": "Chatbot GUI with GR Library"}, "186": {"path": "/mllm/demo/web_demo.py:173-185", "hash": "be56d8ad0241b4a8cc7c2c4bbefc3e3b", "title": "Chatbot Interaction Functions"}, "187": {"path": "/mllm/demo/web_demo.py:186-209", "hash": "abdc5881e69dfb991b5d32f1d36bb163", "title": "Creating GUI App with Code Block Example"}, "188": {"path": "/mllm/demo/web_demo.py:210-222", "hash": "462c10b97b3501c897aaba050cb3d853", "title": "Launch Demo with Sharing Enabled"}, "189": {"path": "/mllm/engine/__init__.py", "hash": "4490de37d641b8087eb0b859fee4557d", "title": "Initializing Trainer Classes"}, "190": {"path": "/mllm/engine/base_engine.py", "hash": "9c9488af6d01f80b9b552001d7eeb68e", "title": "Custom Collator and ML Engine"}, "191": {"path": "/mllm/engine/base_engine.py:1-33", "hash": "1639bf23105ee5e6de8d9c650895deaf", "title": "Customizable Collation Logic for ML Trainers"}, "192": {"path": "/mllm/engine/base_engine.py:34-44", "hash": "24e169a3eb62c10492ee059de4c67b96", "title": "Ignoring Collator: ValueError & Warning in ML Engine"}, "193": {"path": "/mllm/engine/base_engine.py:45-67", "hash": "30c24248bdfa051bdc48ee3bd66452ee", "title": "Custom Data Collator Methods"}, "194": {"path": "/mllm/engine/base_engine.py:68-90", "hash": "f759d11dfa0a4fb6d17b090de746529e", "title": "TrainerForMMLLM Class Definition"}, "195": {"path": "/mllm/engine/base_engine.py:91-114", "hash": "1aa867f995029e529bfa57c9057eac85", "title": "Prediction Step in Model"}, "196": {"path": "/mllm/engine/base_engine.py:115-134", "hash": "e6d4afae3e22047f754c8acccff3d418", "title": "Default Values and Filtering for Generating Text"}, "197": {"path": "/mllm/engine/base_engine.py:135-154", "hash": "971c726953c004b1287f9d91acef5575", "title": "Base Engine Token Generation"}, "198": {"path": "/mllm/engine/base_engine.py:155-175", "hash": "f6d2ac44415cb5468c5515825b802b74", "title": "Token Padding and Masking in ML Engine"}, "199": {"path": "/mllm/engine/base_engine.py:176-193", "hash": "a3785eae55424fb597dab6ed575f8c3e", "title": "Evaluation Metrics Calculation for Generated Tokens"}, "200": {"path": "/mllm/engine/base_engine.py:194-218", "hash": "104d0053a8df18b89fe0ddd930310a58", "title": "Base Engine Class for ML Model"}, "201": {"path": "/mllm/engine/base_engine.py:219-240", "hash": "08de0f1ac2e677d2d3a30f7f901d8d8c", "title": "ML Engine: Save and Log Predictions"}, "202": {"path": "/mllm/engine/base_engine.py:242-259", "hash": "97054ee8ee84c403fd7c0dc09d9964d2", "title": "JSONL Prediction Data Saving"}, "203": {"path": "/mllm/engine/base_engine.py:260-279", "hash": "f4a5c4b894e564896fd89bd30d8a4b6d", "title": "Model OOM Error Prevention"}, "204": {"path": "/mllm/engine/base_engine.py:280-302", "hash": "b3a2dcb3ee0d3e51c016d1baeb930ffe", "title": "Save and Plot Model Training Loss"}, "205": {"path": "/mllm/engine/base_engine.py:305-327", "hash": "536f27c32e1be4409e1c7a7dddf9d67a", "title": "Seq2Seq DataCollator Class with Inference Mode"}, "206": {"path": "/mllm/engine/base_engine.py:328-351", "hash": "cbf8f6ea5eeae62dbe04b3bddc404923", "title": "Data Collator Initialization Code"}, "207": {"path": "/mllm/engine/base_engine.py:352-366", "hash": "8df11fa1c012d03fa2f414190e513d69", "title": "Image and Mask Processing in Model Engine"}, "208": {"path": "/mllm/engine/builder.py", "hash": "3a1a3490d2ecc5374e0c06312861ac3d", "title": "TrainerCollator Builder"}, "209": {"path": "/mllm/engine/nextchat.py", "hash": "0454a254e6886e2aaa809d62c05f8d8b", "title": "Saving NextChatTrainer MM Projector Weights"}, "210": {"path": "/mllm/engine/nextchat.py:1-28", "hash": "81a3b02d53590486254f61139608c5b1", "title": "NextChatTrainer: Saving Model State and Keys"}, "211": {"path": "/mllm/engine/nextchat.py:29-34", "hash": "80faf498589acf12c990456244fb9007", "title": "Create and Save MM Projector Weights"}, "212": {"path": "/mllm/models/__init__.py", "hash": "ea6e69d244739bc5fd30f15d4aee915c", "title": "Importing Pre-trained Models"}, "213": {"path": "/mllm/models/builder/__init__.py", "hash": "ce875895a454ff91f07d1a66efc1e332", "title": "Load Pretrained Models Function"}, "214": {"path": "/mllm/models/builder/build_nextchat.py", "hash": "a07c8809fe5a9efc7e937738db19413d", "title": "NextChat Model Builder"}, "215": {"path": "/mllm/models/builder/build_nextchat.py:1-39", "hash": "a0d7e38ff483edfa839f313d9700fab1", "title": "Build NextChat Model and Tokenizer"}, "216": {"path": "/mllm/models/builder/build_nextchat.py:40-67", "hash": "d0da20dab096c7a174157014cb0764cb", "title": "NExT-Chat Model Initialization"}, "217": {"path": "/mllm/models/builder/build_nextchat.py:68-85", "hash": "15759d56036b68aa85052e50d5099d84", "title": "Initializing Vision Tower for Model"}, "218": {"path": "/mllm/models/builder/build_nextchat.py:86-98", "hash": "958c7cd7f9dbba09ec2df87c4f7f15f0", "title": "Gradient Parameter Check Warning"}, "219": {"path": "/mllm/models/builder/build_nextchat.py:100-126", "hash": "246e2fcd9c699595d380c0abd4841e54", "title": "Nextchat Model Builder: Gradient Control"}, "220": {"path": "/mllm/models/builder/build_nextchat.py:127-156", "hash": "a94fd6133b8c0d452d4799ebf43dec02", "title": "Initialize NextChat Model and Tokenizer"}, "221": {"path": "/mllm/models/builder/build_nextchat.py:157-183", "hash": "2e83d0903e0706cecef2f689ffa5ea45", "title": "Vision Modules Initialization in NextChat"}, "222": {"path": "/mllm/models/builder/build_nextchat.py:184-201", "hash": "b5716f2788608d6a03859e18b9256c58", "title": "CLIP Vision Model Initialization"}, "223": {"path": "/mllm/models/builder/build_nextchat.py:202-216", "hash": "754115e08866fd47a3757ed0bc7b7f28", "title": "Setting Gradients for FSDP Model Components"}, "224": {"path": "/mllm/models/builder/build_nextchat.py:216-240", "hash": "7ca9f8c58bdcce437c4e79f72207e5fc", "title": "Patched FSDP for Model Parameters"}, "225": {"path": "/mllm/models/builder/build_nextchat.py:241-264", "hash": "8d7dacbb51f09bbf8f422cfd29f64b43", "title": "Resizing Model Embeddings"}, "226": {"path": "/mllm/models/builder/builder.py", "hash": "f1411744791e95b4c212c914e0726ee6", "title": "Load Pretrained Models in NExT-Chat Framework"}, "227": {"path": "/mllm/models/nextchat/__init__.py", "hash": "4ca94e5b97ed7658e515012de1b21f22", "title": "Importing NextChat Models"}, "228": {"path": "/mllm/models/nextchat/nextchat_base.py", "hash": "58ee7b9f8dcd6456a93c993857d5b5ec", "title": "Multimodal AI Chat Model Initialization"}, "229": {"path": "/mllm/models/nextchat/nextchat_base.py:1-34", "hash": "739f7e4c9ba187d65ed090690bec044e", "title": "NextChat Llama Model Configuration"}, "230": {"path": "/mllm/models/nextchat/nextchat_base.py:35-54", "hash": "ace8bb0e4131bd979571849a71e6d061", "title": "Vision Modules Initiation"}, "231": {"path": "/mllm/models/nextchat/nextchat_base.py:55-72", "hash": "ed06b34a4b58f6d2548c1b92f4f86579", "title": "Initializing MM Projector for Vision Tower Model"}, "232": {"path": "/mllm/models/nextchat/nextchat_base.py:73-97", "hash": "c01666a2dfc0f8d44f591b34a6cf3670", "title": "Load State Dictionary Method"}, "233": {"path": "/mllm/models/nextchat/nextchat_base.py:99-114", "hash": "a77d34c7be5d4a0facfaec2290028fce", "title": "Retrieving Vision Tower Features"}, "234": {"path": "/mllm/models/nextchat/nextchat_base.py:115-130", "hash": "21771cda1d8b45f35b58de40337eddd8", "title": "Multimodal Input Fusion"}, "235": {"path": "/mllm/models/nextchat/nextchat_base.py:131-143", "hash": "d6f0cc07e5ce05030c712434569f4587", "title": "Image Token Validation"}, "236": {"path": "/mllm/models/nextchat/nextchat_base.py:144-153", "hash": "ecd6c419922e35d5ad5a20305352f91c", "title": "Image End Token Check and Embed Combination"}, "237": {"path": "/mllm/models/nextchat/nextchat_base.py:154-166", "hash": "b89121ad8402195401a4ec6e0b8c7784", "title": "Image Patch Token Check"}, "238": {"path": "/mllm/models/nextchat/nextchat_base.py:167-185", "hash": "6909639b15d31d24a8576a08b3a61289", "title": "Embedding Concatenation for NextChat Model"}, "239": {"path": "/mllm/models/nextchat/nextchat_base.py:186-206", "hash": "0ab1d7ae0d9ddda29d75ded6db4ca02c", "title": "NextChatLlama Model Definition"}, "240": {"path": "/mllm/models/nextchat/nextchat_base.py:207-238", "hash": "d2808195a1a48f1a4c6e03ab8c310303", "title": "NextChatForCausalLM: Llama Model Extension"}, "241": {"path": "/mllm/models/nextchat/nextchat_base.py:239-258", "hash": "b29d221f99b6c1e100c832f021a7f5df", "title": "Initialize Model with Inputs"}, "242": {"path": "/mllm/models/nextchat/nextchat_base.py:259-288", "hash": "eee583ad935ae52613425bd4a6e88768", "title": "NextChat Decoder Outputs"}, "243": {"path": "/mllm/models/nextchat/nextchat_base.py:289-308", "hash": "bb5a6e4df24123c7feba5277cc586b0c", "title": "Flattening Tokens for Parallel Loss Computation"}, "244": {"path": "/mllm/models/nextchat/nextchat_base.py:309-329", "hash": "f4b20f6dad06590718beb5804ef28933", "title": "Object Detection Model Loss Calculation"}, "245": {"path": "/mllm/models/nextchat/nextchat_base.py:330-360", "hash": "982ce069eb0b188961556b3879ec7f99", "title": "Bounding Box Regression and Object Detection Loss Model"}, "246": {"path": "/mllm/models/nextchat/nextchat_base.py:361-388", "hash": "8883ad92a2ebb4f25fcca8e7d435ec1e", "title": "Image-Aware Tokenization"}, "247": {"path": "/mllm/models/nextchat/nextchat_base.py:389-411", "hash": "b3416fd3fc38458eebc9ff6ffbddbab9", "title": "AI Chat System Input Preparation"}, "248": {"path": "/mllm/models/nextchat/nextchat_base.py:412-431", "hash": "db02f4fd656a9915d472f555b3eb5063", "title": "Preparing Model Inputs for NextChat Base"}, "249": {"path": "/mllm/models/nextchat/nextchat_base.py:432-461", "hash": "4f15293c8c5b78e987b2c128ed4cb502", "title": "Model Input Preparation: NextChat Base"}, "250": {"path": "/mllm/models/nextchat/nextchat_base.py:462-480", "hash": "6d77398a87b3d45d6234f9c6eaac2dc1", "title": "Vision Tokenizer Initialization in NextChat Model"}, "251": {"path": "/mllm/models/nextchat/nextchat_base.py:481-498", "hash": "f4214b1399f1a3f6a9201a59b319aa3c", "title": "Resizing Token Embeddings for New Tokens"}, "252": {"path": "/mllm/models/nextchat/nextchat_base.py:499-515", "hash": "a17baf527d570906884649237f227a0d", "title": "Initializing Input Embeddings"}, "253": {"path": "/mllm/models/nextchat/nextchat_base.py:516-520", "hash": "6ce2b803cc2366b56499cbed8441c639", "title": "Shape and Token Count Check"}, "254": {"path": "/mllm/models/nextchat/nextchat_seg.py", "hash": "9f8d686af71b27a6dd73d97fb81c2c47", "title": "NextChat Segmentation Model"}, "255": {"path": "/mllm/models/nextchat/nextchat_seg.py:1-28", "hash": "1e39c9c2b1f62b5fb6fcec481ce45e88", "title": "NextChat Segmented LM Model"}, "256": {"path": "/mllm/models/nextchat/nextchat_seg.py:29-48", "hash": "edde60613f4cf3835454cb41f440c120", "title": "NextChat Segmentation Model"}, "257": {"path": "/mllm/models/nextchat/nextchat_seg.py:49-76", "hash": "466cb475ac040c99306e4a643f1c6896", "title": "NextChat Segment Model Processing"}, "258": {"path": "/mllm/models/nextchat/nextchat_seg.py:77-94", "hash": "320dc8db3625827048daa8a948f04097", "title": "NextChat Segmentation Model Code"}, "259": {"path": "/mllm/models/nextchat/nextchat_seg.py:95-123", "hash": "5a319dc30beed58a79c5da9a1d49fbf2", "title": "Located Image Embedding Model"}, "260": {"path": "/mllm/models/nextchat/nextchat_seg.py:125-147", "hash": "e8cfa17311a0a94f7f77e575989fd4d9", "title": "NextChat Model Text Generation"}, "261": {"path": "/mllm/models/nextchat/nextchat_seg.py:148-167", "hash": "cffaf8e311d9fc906d737767fcf53a71", "title": "Vision Tower Detection in Model Outputs"}, "262": {"path": "/mllm/models/nextchat/nextchat_seg.py:168-186", "hash": "a18e2378ba62e46c4240b69949ffa364", "title": "Prepare Inputs for Model Generation"}, "263": {"path": "/mllm/models/nextchat/nextchat_seg.py:187-208", "hash": "a7b81e38738304ebc7424d251fe1511f", "title": "NextChat Segment Embedding"}, "264": {"path": "/mllm/models/nextchat/nextchat_seg.py:209-223", "hash": "1062f15ec4c2e1821849425ea82d3cd3", "title": "Chat Model Input Preparation"}, "265": {"path": "/mllm/models/sam/modeling_sam.py", "hash": "5bcf74395e17f0e9e24a70f3513ad0ee", "title": "Multi-Head Attention for Image Encoding"}, "266": {"path": "/mllm/models/sam/modeling_sam.py:1-35", "hash": "0a4ea93bd2bf0d415214bc5e05e826ba", "title": "Multilayer Perceptron Module Definition"}, "267": {"path": "/mllm/models/sam/modeling_sam.py:36-70", "hash": "86d738193646a0da887f34865eb2123d", "title": "Layer Normalized Transformer Decoder"}, "268": {"path": "/mllm/models/sam/modeling_sam.py:71-96", "hash": "4c7d5989003412b9c14934647ef99a76", "title": "Transformer Model Architecture: TwoWayAttentionBlock"}, "269": {"path": "/mllm/models/sam/modeling_sam.py:97-124", "hash": "7a9623f97be198010d3d1aa2453d990d", "title": "Sam Image Attention Model"}, "270": {"path": "/mllm/models/sam/modeling_sam.py:125-158", "hash": "fc21f8305f8762d19acd69540498648b", "title": "TwoWayAttention Block for Point-Image Transformers"}, "271": {"path": "/mllm/models/sam/modeling_sam.py:159-182", "hash": "55764d64fb79e7aa4014838c3dc725c1", "title": "Sparse-Dense Transformer Block Code"}, "272": {"path": "/mllm/models/sam/modeling_sam.py:184-210", "hash": "c0796c96c7d3571b7d432bca96cf0bb6", "title": "MLPBlock Attention Layer in Transformer Model"}, "273": {"path": "/mllm/models/sam/modeling_sam.py:211-246", "hash": "78f44c87556cef5a48714d4088725e15", "title": "Downsampling Attention Layer"}, "274": {"path": "/mllm/models/sam/modeling_sam.py:247-273", "hash": "491e1a4d1d1365f40c1042bac19f5867", "title": "Multi-Head Attention Layer"}, "275": {"path": "/mllm/models/sam/modeling_sam.py:274-306", "hash": "ffbdd2b72681852e4411d9bbcc88431c", "title": "Vision Transformer Image Encoder"}, "276": {"path": "/mllm/models/sam/modeling_sam.py:307-328", "hash": "eeeb54768ecf0e695f9691bf19e1094f", "title": "Vision Transformer Parameters Init"}, "277": {"path": "/mllm/models/sam/modeling_sam.py:329-355", "hash": "9ec7fe5db7bef91699abdab1aff392a4", "title": "Sam Model Initialization"}, "278": {"path": "/mllm/models/sam/modeling_sam.py:356-389", "hash": "22aa2501a3acb29d5bee331705746f0e", "title": "Vision Transformer Model Initialization"}, "279": {"path": "/mllm/models/sam/modeling_sam.py:390-421", "hash": "f3579f39b035dda2d4e8e2b31d635e4f", "title": "Windowed Transformer Block Class"}, "280": {"path": "/mllm/models/sam/modeling_sam.py:422-447", "hash": "0cac008915749d2367461954bbf07f7d", "title": "Attention Block Initialization"}, "281": {"path": "/mllm/models/sam/modeling_sam.py:448-480", "hash": "ad7228be7e3737e580f1fef6660e9de7", "title": "Multi-Head Attention Block with Relative Positions"}, "282": {"path": "/mllm/models/sam/modeling_sam.py:481-504", "hash": "f27f9b58c15267d1b5a8fad3ccf2c07f", "title": "Multi-Head Attention Layer for Transformers"}, "283": {"path": "/mllm/models/sam/modeling_sam.py:505-531", "hash": "1fce7c5770fcea6e18525f1480fe90a3", "title": "Non-overlapping Window Partitioning with Padding"}, "284": {"path": "/mllm/models/sam/modeling_sam.py:532-559", "hash": "fea6dc3398a109604a6d51f7ab744fd0", "title": "Sam: Windowize Sequences"}, "285": {"path": "/mllm/models/sam/modeling_sam.py:560-587", "hash": "9d5c25cbd3d50f289a8b6a7806eee257", "title": "Windows and Positional Embeddings Functions"}, "286": {"path": "/mllm/models/sam/modeling_sam.py:588-615", "hash": "edf4b7a6d02709632e537c9b5c8dfbcc", "title": "Decomposed Relative Positional Embeddings Calculator"}, "287": {"path": "/mllm/models/sam/modeling_sam.py:616-647", "hash": "01535474e79761b57a039a1a80076262", "title": "SAM Patch Embedding Function"}, "288": {"path": "/mllm/models/sam/modeling_sam.py:648-680", "hash": "19cc24e88df3ea1cf629f055257d84a6", "title": "Conv2d Layer for Patch Embedding"}, "289": {"path": "/mllm/models/sam/modeling_sam.py:681-709", "hash": "4f8f05a43e97c91d907b6f937f070f4e", "title": "MaskDecoder Class for Predicting Masks"}, "290": {"path": "/mllm/models/sam/modeling_sam.py:710-736", "hash": "60a2bcdb41a4b191aac373d77a5330c7", "title": "Transformer Image Segmentation Model"}, "291": {"path": "/mllm/models/sam/modeling_sam.py:737-763", "hash": "553ed2f1f9ec3e2feab4f9a655eb874e", "title": "Sam: Mask Generation Function"}, "292": {"path": "/mllm/models/sam/modeling_sam.py:764-791", "hash": "086377d7f28eafeaa1f7dc73ea2424b6", "title": "Model for Mask Prediction in SAM"}, "293": {"path": "/mllm/models/sam/modeling_sam.py:793-814", "hash": "e45aed5ff19fef1e3a091c71e216b9f7", "title": "Mask Token Generation and Upscaling"}, "294": {"path": "/mllm/models/sam/modeling_sam.py:815-845", "hash": "acbb6c3db5ada46f8b29396430ca38dc", "title": "Sigmoid-MLP: Adapted from MaskFormer"}, "295": {"path": "/mllm/models/sam/modeling_sam.py:846-879", "hash": "e42673eb77bcb0be646a4b1f10a68a37", "title": "PromptEncoder Class: Encoding Inputs for SAM"}, "296": {"path": "/mllm/models/sam/modeling_sam.py:880-901", "hash": "980728ec531e715d5a422d2f1b66c20e", "title": "Sam Model Embedding Initialization"}, "297": {"path": "/mllm/models/sam/modeling_sam.py:902-929", "hash": "b57451c3e76f22787e1828cf4e538115", "title": "Point Prompt Embedding in Image Encoding Model"}, "298": {"path": "/mllm/models/sam/modeling_sam.py:930-952", "hash": "39792d787cff22ff15105139a78bedc8", "title": "Multi-Modal Embedding in SAM Model"}, "299": {"path": "/mllm/models/sam/modeling_sam.py:953-984", "hash": "bb3babf367dcd027c20357cef707fcb0", "title": "Batch Size and Embedding Function"}, "300": {"path": "/mllm/models/sam/modeling_sam.py:985-1003", "hash": "d540993da3264e172cd24e88ec352d07", "title": "Sparse and Dense Embeddings Generation"}, "301": {"path": "/mllm/models/sam/modeling_sam.py:1005-1032", "hash": "003c51ad8c11003219b39330d8462932", "title": "Sam Model: Mask Embedding and Random Positional Encoding"}, "302": {"path": "/mllm/models/sam/modeling_sam.py:1033-1055", "hash": "fd23e7f698c7f053003bf544d1171d17", "title": "Positional Encoding Class for SAM Model"}, "303": {"path": "/mllm/models/sam/modeling_sam.py:1056-1088", "hash": "fe806c91ecbd7fd6b361183a2b17ad4c", "title": "SAM Model: Initializing Attributes and Encoding"}, "304": {"path": "/mllm/models/sam/modeling_sam.py:1089-1113", "hash": "f1e8185c337dec96cb9faa24010f470a", "title": "Sam Model: Mask Prediction from Images and Prompts"}, "305": {"path": "/mllm/models/sam/modeling_sam.py:1114-1131", "hash": "b8b8690c769889fce5fecec062b5435d", "title": "SamPredictor Model Function Signature"}, "306": {"path": "/mllm/models/sam/modeling_sam.py:1132-1150", "hash": "142ecf5a3df20a4de3f68489e56cd85f", "title": "Batched Image Preprocessing for SAM Model"}, "307": {"path": "/mllm/models/sam/modeling_sam.py:1151-1173", "hash": "972ea406a591adf3f878877e31de3e02", "title": "Image-Based Text Generation with Separate Encoders and Decoders"}, "308": {"path": "/mllm/models/sam/modeling_sam.py:1174-1203", "hash": "31c357218654203d10b7e356f93c1493", "title": "Mask Decoder for Sam Model"}, "309": {"path": "/mllm/models/sam/modeling_sam.py:1204-1231", "hash": "0f10a047477cf73e363fe002dca5097d", "title": "Sam Model: Masks and Preprocessing"}, "310": {"path": "/mllm/models/sam/modeling_sam.py:1232-1279", "hash": "12d13580777b35d11fc509f6236a3696", "title": "SAM Model Implementations in MLMM"}, "311": {"path": "/mllm/models/sam/modeling_sam.py:1280-1314", "hash": "429ed24fe5d646bc54fbd4284f7f4ad6", "title": "Building SAM with ViT Encoders"}, "312": {"path": "/mllm/models/sam/modeling_sam.py:1315-1348", "hash": "496c16fbe70c41ecc7d7ab7270d81469", "title": "Sam For LM Segmentation Class"}, "313": {"path": "/mllm/models/sam/modeling_sam.py:1349-1380", "hash": "236e1ad2ab97b1ddc3b3f9839420a6b1", "title": "Image-Prompt Mask Generation Model"}, "314": {"path": "/mllm/models/sam/modeling_sam.py:1382-1404", "hash": "4b4496f9486877a96a454bdee357815f", "title": "Predict Method for Model's Image Features"}, "315": {"path": "/mllm/models/sam/modeling_sam.py:1405-1422", "hash": "b6e6a8119c4e7a5f81662e63cc91c674", "title": "Preparing Inputs for SAM Model Predictions"}, "316": {"path": "/mllm/models/sam/modeling_sam.py:1423-1449", "hash": "87fc2dd146c341b6013c7fe8620096b7", "title": "Masked Sparse Embedding Logits Function"}, "317": {"path": "/mllm/models/sam/modeling_sam.py:1450-1473", "hash": "c47f32cee8a08219dc2cea3e197d2fa7", "title": "Mask and IOU Prediction in Sam Model"}, "318": {"path": "/mllm/models/sam/sam_loss.py", "hash": "08d7ef3a699d55a7dccf87e6037c31ec", "title": "Custom Loss Functions for Segmentation Models"}, "319": {"path": "/mllm/models/sam/sam_loss.py:1-37", "hash": "f19d85078c058c6cd5691468fdbe2d0e", "title": "Custom Loss Functions for Imbalanced Datasets"}, "320": {"path": "/mllm/models/sam/sam_loss.py:39-68", "hash": "b012126d6413d135dff40763db7cf64b", "title": "SamLoss: Focal, Dice, and IoU Losses"}, "321": {"path": "/mllm/models/sam/sam_loss.py:69-75", "hash": "050bb4de3d4a63904a995a2475227e1f", "title": "Multi-Loss Segmentation Model Evaluator"}, "322": {"path": "/mllm/models/sam/transforms.py", "hash": "c3fa17956efeb12d932d51bbe73187b2", "title": "Image Resizing and Padding Transforms"}, "323": {"path": "/mllm/models/sam/transforms.py:1-33", "hash": "7e5153d0d39c449e9e82c83c9615d038", "title": "ResizeLongestSide Class"}, "324": {"path": "/mllm/models/sam/transforms.py:34-56", "hash": "075b5036d2a169c43ceeae66eeb199a3", "title": "Image Resizing and Transformations Class"}, "325": {"path": "/mllm/models/sam/transforms.py:57-81", "hash": "d0b6ddd0263475cc8470f8392542fe2d", "title": "Image and Coordinate Transforms for Deep Learning Models"}, "326": {"path": "/mllm/models/sam/transforms.py:82-108", "hash": "1436728a08d9775e72d161a4edbc6a53", "title": "Image Box Transforms: Preprocessing Functions"}, "327": {"path": "/mllm/models/sam/transforms.py:109-138", "hash": "ed74facd21b1de582f36ad44b74ee9a9", "title": "ResizeAndPad Class"}, "328": {"path": "/mllm/models/sam/transforms.py:140-149", "hash": "281050ccb1e3823ffd608d8403a71a8f", "title": "Padding and Adjusting Bounding Boxes"}, "329": {"path": "/mllm/pipeline/finetune.py", "hash": "9f543cb311072fa73ccc636054f4494c", "title": "Fine-tuning ML Models Pipeline"}, "330": {"path": "/mllm/pipeline/finetune.py:1-36", "hash": "a360087472543e0d5dfcbdd303a35060", "title": "ML Model Training Environment Setup"}, "331": {"path": "/mllm/pipeline/finetune.py:37-59", "hash": "4d2dee8fa7f4d5cc79699503b2fea05c", "title": "Finetune Model with Trainer"}, "332": {"path": "/mllm/pipeline/finetune.py:60-83", "hash": "245e6a627724739da300d52862ea5cdd", "title": "Error-handling Finetune Trainer"}, "333": {"path": "/mllm/pipeline/finetune.py:85-100", "hash": "a4d4167d36ecdcea03144779820149dc", "title": "Default Values and Token Handling in Finetune Py Pipeline"}, "334": {"path": "/mllm/pipeline/finetune.py:101-118", "hash": "8ffdbfa0ab5ce425fe6a32a41387c235", "title": "Multi-predict Collator Warning"}, "335": {"path": "/mllm/pipeline/finetune.py:119-141", "hash": "84a8baaaa2e4a7f852ef7204ed7d242d", "title": "Multi-test Pipeline Metrics Processing"}, "336": {"path": "/mllm/pipeline/finetune_mem.py", "hash": "a63b3284cc06557bbc971b1cd6611a33", "title": "Memory-Efficient LLaMA with FlashAttn"}, "337": {"path": "/mllm/utils/__init__.py", "hash": "538d6cdc1cf7be50e07cdda1e664093b", "title": "Utility Functions for ML/CV Projects"}, "338": {"path": "/mllm/utils/box_ops.py", "hash": "299338ecd308335e448a466b43a2f6b3", "title": "Bounding Box Utilities for Masks"}, "339": {"path": "/mllm/utils/box_ops.py:1-41", "hash": "1318b5703fb72324f308cfead8b1bfa8", "title": "Bounding Box Utilities and GIoU Calculator"}, "340": {"path": "/mllm/utils/box_ops.py:42-76", "hash": "3ee840fdcd43d628894e12c5e5c3fad2", "title": "Bounding Box Utilities in NExT-Chat"}, "341": {"path": "/mllm/utils/box_ops.py:77-103", "hash": "c70cc4eb440b6320dcbd1d86ef83421b", "title": "Min/Max Coord Calculator"}, "342": {"path": "/mllm/utils/box_ops.py:104-116", "hash": "81a632ca4d12efd5b93e4cabdf1e4b3e", "title": "Interpolation Method Based on Torchvision Version"}, "343": {"path": "/mllm/utils/common.py", "hash": "4c9211618e538ffebdc57bc53b26791a", "title": "Multi-Task Text and Image Processing"}, "344": {"path": "/mllm/utils/common.py:1-36", "hash": "79e618a0d03039384a6821ff66c72011", "title": "Trainable Parameters Count"}, "345": {"path": "/mllm/utils/common.py:37-63", "hash": "a297815f193587e6cd13fcadc061e379", "title": "Multi-Function Utilities for ML Tasks"}, "346": {"path": "/mllm/utils/common.py:66-94", "hash": "fa2f8d9c25f7c50d46a5febc1d11631d", "title": "Multi-Function Utils: Drawing Boxes and Resizing Embeddings"}, "347": {"path": "/mllm/utils/common.py:95-124", "hash": "df3870dda726c1bdb8e22099d5b878fd", "title": "Token Embedding Resizer and ImageBoxState Class"}, "348": {"path": "/mllm/utils/common.py:125-160", "hash": "937450c14cd9bee3ae5a726335b79b42", "title": "Class Methods for Resetting Masks and Images"}, "349": {"path": "/mllm/utils/common.py:161-186", "hash": "8eab9135dcf253fea4e83de3e8931b62", "title": "Image Box Handling Functions"}, "350": {"path": "/mllm/utils/common.py:187-205", "hash": "b9aa4e10ef1651688e0a5364c0e0c56e", "title": "Bounding Box Annotations on Images"}, "351": {"path": "/mllm/utils/common.py:206-240", "hash": "3523c444049e40a201ad22c2f8e96d85", "title": "Image Parsing and Processing Functions"}, "352": {"path": "/mllm/utils/common.py:241-245", "hash": "87d92366b78bfc955120a58ec8513592", "title": "Formatting Text with Substrings"}, "353": {"path": "/requirements.txt", "hash": "defbfb79d7cfb83cf2706bd37e1e3fe9", "title": "Python Project Dependencies"}, "354": {"path": "/run_stage1.sh", "hash": "30c255b2f638a4bdcab362a963512c07", "title": "Launch Multimodal Model Fine-tuning Script"}, "355": {"path": "/run_stage2.sh", "hash": "94b9d07697fb8f5af9dfa31b61d29749", "title": "Auto-training Stage 2 Model (/run_stage2.sh)"}, "356": {"path": "/run_stage3.sh", "hash": "5d4777876d59068c10e66cd943a15c6c", "title": "Stage 3 Model Training Initiation"}}}